#!/bin/bash

# Safety LoRA è®­ç»ƒ - ä½¿ç”¨ SVD + æ­£äº¤è¡¥æŠ•å½±åˆå§‹åŒ–
# è¿™æ˜¯ç†è®ºæœ€ä¼˜çš„åˆå§‹åŒ–æ–¹æ³•
# 
# ğŸ†• æ”¯æŒå±‚åŒºé—´çº¦æŸ:
#   --constrained_layers all            # æ‰€æœ‰å±‚ (é»˜è®¤)
#   --constrained_layers 8-16           # ä»…çº¦æŸ 8-16 å±‚
#   --constrained_layers 8-16,20-24     # çº¦æŸ 8-16 å’Œ 20-24 å±‚
#   --constrained_layers 0-8            # ä»…çº¦æŸå‰ 9 å±‚
#
# ç”¨æ³•:
#   bash train_safety_svd_ortho.sh              # ä½¿ç”¨é»˜è®¤é…ç½® (all)
#   bash train_safety_svd_ortho.sh 8-16         # ä»…çº¦æŸ 8-16 å±‚
#   bash train_safety_svd_ortho.sh 8-16,20-24   # çº¦æŸå¤šä¸ªåŒºé—´

# ä»å‘½ä»¤è¡Œå‚æ•°è·å–å±‚åŒºé—´é…ç½®ï¼Œé»˜è®¤ä¸º 'all'
CONSTRAINED_LAYERS="${1:-all}"

echo "ğŸš€ å¼€å§‹è®­ç»ƒ: Safety LoRA (SVD + æ­£äº¤è¡¥æŠ•å½±åˆå§‹åŒ–)"
echo "ğŸ¯ çº¦æŸå±‚èŒƒå›´: $CONSTRAINED_LAYERS"

python train_v2_main.py \
    --model_name Qwen/Qwen2.5-1.5B-Instruct \
    --dataset_type ultrafeedback \
    --dataset_size full \
    --data_format instruction \
    --output_dir ./output/helpfulness-lora_wo_g_r16_a32-ep1-svd_rank16-salora_24_27-lr_5e-5 \
    --gpu_id 0 \
    \
    --lora_rank 16 \
    --lora_alpha 32 \
    --lora_dropout 0.01 \
    --target_modules q_proj k_proj v_proj o_proj up_proj down_proj \
    --lora_init_method svd_salora \
    --use_hard_constraint \
    --svd_niter 30 \
    \
    --num_epochs 1 \
    --batch_size 1 \
    --gradient_accumulation 8 \
    --learning_rate 5e-5 \
    --max_length 512 \
    --use_gradient_checkpointing \
    \
    --subspace_dir ../preference_subspace/saved_subspaces \
    --preference_dimensions safety \
    --constrained_layers "$CONSTRAINED_LAYERS" \
    \
    --use_swanlab true \
    --swanlab_project protected-lora \
    --experiment_name "helpfulness-lora_wo_g_r16_a32-ep1-svd_rank16-salora_24_27-lr_5e-5" \
    --print_interval 10

echo "âœ… è®­ç»ƒå®Œæˆ"
echo "ğŸ¯ çº¦æŸå±‚èŒƒå›´: $CONSTRAINED_LAYERS"
