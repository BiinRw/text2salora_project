#!/bin/bash

# è®­ç»ƒæ‰€æœ‰ç»´åº¦çš„å¤šä½ç½®æ¢é’ˆ
# æ”¯æŒåŒæ—¶è®­ç»ƒ: user_last, assistant_first, assistant_last, assistant_mean

MODEL_NAME="Qwen/Qwen2.5-1.5B-Instruct"
DEVICE="cuda:3"

DATA_DIR="data"
OUTPUT_DIR="results_multi_position"

mkdir -p $OUTPUT_DIR

echo "========================================="
echo "ğŸš€ å¤šä½ç½®æ¢é’ˆè®­ç»ƒ - æ‰€æœ‰ç»´åº¦"
echo "========================================="
echo "æ¨¡å‹: $MODEL_NAME"
echo "è®¾å¤‡: $DEVICE"
echo "ä½ç½®: user_last, assistant_first, assistant_last, assistant_mean"
echo "========================================="

# å®šä¹‰è¦è®­ç»ƒçš„ä½ç½®
POSITIONS="user_last assistant_first assistant_last assistant_mean"

# 1. è®­ç»ƒå®‰å…¨æ€§æ¢é’ˆ
echo ""
echo "ğŸ“Š [1/6] è®­ç»ƒå®‰å…¨æ€§å¤šä½ç½®æ¢é’ˆ..."
python train_multi_position_probes.py \
    --model_name $MODEL_NAME \
    --device $DEVICE \
    --good_pairs ${DATA_DIR}/safety_paired/safe_pairs_large.json \
    --bad_pairs ${DATA_DIR}/safety_paired/harmful_pairs_large.json \
    --max_samples 1000 \
    --positions $POSITIONS \
    --test_split 0.2 \
    --cv_folds 5 \
    --max_iter 2000 \
    --reg_C 1.0 \
    --output_dir ${OUTPUT_DIR}/safety \
    --dimension safety

# 2-6. è®­ç»ƒHelpSteerå„ç»´åº¦æ¢é’ˆ
dimensions=("helpfulness" "correctness" "coherence" "complexity" "verbosity")
dim_names=("æœ‰ç”¨æ€§" "æ­£ç¡®æ€§" "è¿è´¯æ€§" "å¤æ‚æ€§" "å†—é•¿åº¦")

for i in "${!dimensions[@]}"; do
    dim=${dimensions[$i]}
    name=${dim_names[$i]}
    idx=$((i+2))
    
    echo ""
    echo "ğŸ“Š [$idx/6] è®­ç»ƒ${name}å¤šä½ç½®æ¢é’ˆ ($dim)..."
    python train_multi_position_probes.py \
        --model_name $MODEL_NAME \
        --device $DEVICE \
        --good_pairs ${DATA_DIR}/helpsteer_paired/${dim}_good_pairs.json \
        --bad_pairs ${DATA_DIR}/helpsteer_paired/${dim}_bad_pairs.json \
        --max_samples 1000 \
        --positions $POSITIONS \
        --test_split 0.2 \
        --cv_folds 5 \
        --max_iter 2000 \
        --reg_C 1.0 \
        --output_dir ${OUTPUT_DIR}/${dim} \
        --dimension ${dim}
done

echo ""
echo "========================================="
echo "âœ… æ‰€æœ‰ç»´åº¦å¤šä½ç½®è®­ç»ƒå®Œæˆ!"
echo "========================================="
echo "ğŸ“‚ ç»“æœç›®å½•: $OUTPUT_DIR/"
echo ""

# ç”Ÿæˆæ€»ä½“å¯¹æ¯”æŠ¥å‘Š
echo "ğŸ“ ç”Ÿæˆæ€»ä½“å¯¹æ¯”æŠ¥å‘Š..."
python << 'EOFREPORT'
import json
import os
import numpy as np

output_dir = "results_multi_position"
dimensions = [
    ('safety', 'å®‰å…¨æ€§'),
    ('helpfulness', 'æœ‰ç”¨æ€§'),
    ('correctness', 'æ­£ç¡®æ€§'),
    ('coherence', 'è¿è´¯æ€§'),
    ('complexity', 'å¤æ‚æ€§'),
    ('verbosity', 'å†—é•¿åº¦')
]

positions = ['user_last', 'assistant_first', 'assistant_last', 'assistant_mean']
position_names = {
    'user_last': 'ç”¨æˆ·æœ«token',
    'assistant_first': 'åŠ©æ‰‹é¦–token',
    'assistant_last': 'åŠ©æ‰‹æœ«token',
    'assistant_mean': 'åŠ©æ‰‹å¹³å‡'
}

summary_file = os.path.join(output_dir, "å…¨ç»´åº¦ä½ç½®å¯¹æ¯”æŠ¥å‘Š.txt")

with open(summary_file, 'w', encoding='utf-8') as f:
    f.write("="*80 + "\n")
    f.write("ï¿½ï¿½ å…¨ç»´åº¦å¤šä½ç½®æ¢é’ˆå¯¹æ¯”æŠ¥å‘Š\n")
    f.write("="*80 + "\n\n")
    f.write(f"è®­ç»ƒç»´åº¦: {len(dimensions)} ä¸ª\n")
    f.write(f"è®­ç»ƒä½ç½®: {len(positions)} ä¸ª\n")
    f.write(f"ä½ç½®åˆ—è¡¨: {', '.join([position_names[p] for p in positions])}\n")
    f.write("\n" + "="*80 + "\n\n")
    
    # ä¸ºæ¯ä¸ªç»´åº¦ç”ŸæˆæŠ¥å‘Š
    for dim_key, dim_name in dimensions:
        f.write(f"\nğŸ“Œ {dim_name} ({dim_key})\n")
        f.write("-"*80 + "\n")
        
        dim_dir = os.path.join(output_dir, dim_key)
        if not os.path.exists(dim_dir):
            f.write("   âŒ æœªæ‰¾åˆ°è®­ç»ƒç»“æœ\n")
            continue
        
        position_stats = {}
        
        for pos in positions:
            result_file = os.path.join(dim_dir, f"{dim_key}_{pos}_results.json")
            if not os.path.exists(result_file):
                continue
            
            with open(result_file, 'r') as rf:
                results = json.load(rf)
            
            test_accs = [r['test_accuracy'] for r in results.values()]
            cv_means = [r['cv_mean'] for r in results.values()]
            
            position_stats[pos] = {
                'avg_acc': np.mean(test_accs),
                'max_acc': np.max(test_accs),
                'ge_80': sum(1 for a in test_accs if a >= 0.8),
                'ge_90': sum(1 for a in test_accs if a >= 0.9),
                'avg_cv': np.mean(cv_means)
            }
        
        # æŒ‰å¹³å‡å‡†ç¡®ç‡æ’åº
        sorted_positions = sorted(position_stats.items(), 
                                 key=lambda x: x[1]['avg_acc'], 
                                 reverse=True)
        
        f.write(f"\n   ä½ç½®æ€§èƒ½æ’å:\n")
        for rank, (pos, stats) in enumerate(sorted_positions, 1):
            pos_name = position_names[pos]
            f.write(f"   {rank}. {pos_name:12s} ")
            f.write(f"å¹³å‡: {stats['avg_acc']:.4f}  ")
            f.write(f"æœ€é«˜: {stats['max_acc']:.4f}  ")
            f.write(f">=0.8: {stats['ge_80']:3d}  ")
            f.write(f">=0.9: {stats['ge_90']:3d}\n")
        
        # æ‰¾å‡ºæœ€ä½³ä½ç½®
        if sorted_positions:
            best_pos, best_stats = sorted_positions[0]
            f.write(f"\n   ğŸ† æœ€ä½³ä½ç½®: {position_names[best_pos]} ")
            f.write(f"(å¹³å‡å‡†ç¡®ç‡: {best_stats['avg_acc']:.4f})\n")
    
    # æ€»ä½“ç»Ÿè®¡
    f.write("\n" + "="*80 + "\n")
    f.write("ğŸ“Š è·¨ç»´åº¦ä½ç½®æ€§èƒ½å¯¹æ¯”\n")
    f.write("="*80 + "\n")
    
    # ç»Ÿè®¡æ¯ä¸ªä½ç½®åœ¨å„ç»´åº¦çš„å¹³å‡è¡¨ç°
    position_overall = {pos: [] for pos in positions}
    
    for dim_key, dim_name in dimensions:
        dim_dir = os.path.join(output_dir, dim_key)
        if not os.path.exists(dim_dir):
            continue
        
        for pos in positions:
            result_file = os.path.join(dim_dir, f"{dim_key}_{pos}_results.json")
            if not os.path.exists(result_file):
                continue
            
            with open(result_file, 'r') as rf:
                results = json.load(rf)
            
            test_accs = [r['test_accuracy'] for r in results.values()]
            position_overall[pos].append(np.mean(test_accs))
    
    f.write("\nå„ä½ç½®è·¨æ‰€æœ‰ç»´åº¦çš„å¹³å‡æ€§èƒ½:\n")
    overall_ranking = []
    for pos in positions:
        if position_overall[pos]:
            avg_performance = np.mean(position_overall[pos])
            overall_ranking.append((pos, avg_performance))
    
    overall_ranking.sort(key=lambda x: x[1], reverse=True)
    
    for rank, (pos, avg_perf) in enumerate(overall_ranking, 1):
        pos_name = position_names[pos]
        f.write(f"   {rank}. {pos_name:12s}: {avg_perf:.4f}\n")
    
    f.write("\n" + "="*80 + "\n")
    f.write("âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆ\n")
    f.write(f"ğŸ’¾ å„ç»´åº¦è¯¦ç»†ç»“æœä¿å­˜åœ¨: {output_dir}/*/\n")
    f.write("="*80 + "\n")

print(f"âœ… æ€»ä½“å¯¹æ¯”æŠ¥å‘Šå·²ä¿å­˜: {summary_file}")
EOFREPORT

echo ""
echo "ğŸ“„ æŸ¥çœ‹æŠ¥å‘Š:"
cat "${OUTPUT_DIR}/å…¨ç»´åº¦ä½ç½®å¯¹æ¯”æŠ¥å‘Š.txt"

echo ""
echo "========================================="
echo "ğŸ‰ å…¨éƒ¨å®Œæˆ!"
echo "========================================="
