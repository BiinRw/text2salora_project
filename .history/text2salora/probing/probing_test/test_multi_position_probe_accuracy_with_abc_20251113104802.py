"""
Multi-position Probe Accuracy Test with ABC Constraints

Differences from test_multi_position_probe_accuracy.py:
- Added subspace constraint C loading and application
- Delta_W = B @ A @ C, where C = I - V @ V^T
- Other configs (data loading, probe loading, position extraction) remain the same

Key configurations:
1. Data: Priority {dimension}_good/bad_pairs.json, fallback safe/harmful_pairs_large.json
2. Probes: {probe_dir}/{dimension}_{position}_probes/layer-X-head-Y.pkl
3. Position: assistant_last = len(tokens) - 1
4. Labels: good=1, bad=0
"""


import torch
import numpy as np
from sklearn.metrics import accuracy_score, precision_recall_fscore_support
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel
from tqdm import tqdm
import json
import argparse
import os
import pickle
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple


class ABCConstraintLoader:
    """Load and apply ABC constraints (C = I - V @ V^T)"""
    
    def __init__(self, subspace_dir, dimension, device='cuda:0', constrained_layers=None):
        self.subspace_dir = Path(subspace_dir)
        self.dimension = dimension
        self.device = device
        self.subspaces = {}
        self.constrained_layers = constrained_layers  # Noneè¡¨ç¤ºæ‰€æœ‰å±‚, æˆ–è€…(start, end)å…ƒç»„
        
    def load_subspaces(self):
        """Load subspace V matrices for all layers from per-layer files"""
        import re
        
        # å°è¯•æ ¼å¼1: {dimension}_subspaces.pt (å•æ–‡ä»¶)
        single_file = self.subspace_dir / f"{self.dimension}_subspaces.pt"
        
        if single_file.exists():
            print(f"\nğŸ”„ Loading subspace from single file: {single_file}")
            data = torch.load(single_file, map_location='cpu', weights_only=False)
            for layer_id, V in data.items():
                if isinstance(V, torch.Tensor):
                    self.subspaces[layer_id] = V.to(self.device)
            print(f"   âœ… Loaded {len(self.subspaces)} layer subspaces")
            return True
        
        # æ ¼å¼2: {dimension}_layer{N}_subspace.pt (æ¯å±‚ä¸€ä¸ªæ–‡ä»¶)
        print(f"\nğŸ”„ Loading subspace from per-layer files...")
        print(f"   Directory: {self.subspace_dir}")
        print(f"   Pattern: {self.dimension}_layer*_subspace.pt")
        
        layer_files = sorted(self.subspace_dir.glob(f"{self.dimension}_layer*_subspace.pt"))
        
        if not layer_files:
            print(f"âš ï¸  Warning: No subspace files found!")
            print(f"   Running without ABC constraints")
            return False
        
        for layer_file in layer_files:
            # æå–å±‚å·
            match = re.search(r'layer(\d+)_subspace\.pt', layer_file.name)
            if not match:
                continue
            
            layer_id = int(match.group(1))
            
            # åŠ è½½æ•°æ®
            data = torch.load(layer_file, map_location='cpu', weights_only=False)
            
            # æå– V çŸ©é˜µ
            if isinstance(data, dict) and 'V' in data:
                V = data['V']
            elif isinstance(data, torch.Tensor):
                V = data
            else:
                continue
            
            self.subspaces[layer_id] = V.to(self.device)
        
        print(f"   âœ… Loaded {len(self.subspaces)} layer subspaces")
        layer_ids = sorted(self.subspaces.keys())
        print(f"   ğŸ“Š Layers: [{layer_ids[0]}...{layer_ids[-1]}]")
        return True

        
        # æ ¼å¼2: {dimension}_layer{N}_subspace.pt (æ¯å±‚ä¸€ä¸ªæ–‡ä»¶)
        print(f"\nğŸ”„ Loading subspace from per-layer files...")
        print(f"   Directory: {self.subspace_dir}")
        print(f"   Pattern: {self.dimension}_layer*_subspace.pt")
        
        layer_files = sorted(self.subspace_dir.glob(f"{self.dimension}_layer*_subspace.pt"))
        
        if not layer_files:
            print(f"âš ï¸  Warning: No subspace files found!")
            print(f"   Running without ABC constraints")
            return False
        
        for layer_file in layer_files:
            # æå–å±‚å·
            match = re.search(r'layer(\d+)_subspace\.pt', layer_file.name)
            if not match:
                continue
            
            layer_id = int(match.group(1))
            
            # åŠ è½½æ•°æ®
            data = torch.load(layer_file, map_location='cpu', weights_only=False)
            
            # æå– V çŸ©é˜µ
            if isinstance(data, dict) and 'V' in data:
                V = data['V']
            elif isinstance(data, torch.Tensor):
                V = data
            else:
                continue
            
            self.subspaces[layer_id] = V.to(self.device)
        
        print(f"   âœ… Loaded {len(self.subspaces)} layer subspaces")
        layer_ids = sorted(self.subspaces.keys())
        print(f"   ğŸ“Š Layers: [{layer_ids[0]}...{layer_ids[-1]}]")
        return True

    
    def compute_constraint_matrix(self, layer_id, hidden_dim):
        """
        # æ£€æŸ¥è¯¥å±‚æ˜¯å¦éœ€è¦åº”ç”¨çº¦æŸ
        if self.constrained_layers is not None:
            start, end = self.constrained_layers
            if not (start <= layer_id <= end):
                # è¯¥å±‚ä¸åœ¨çº¦æŸèŒƒå›´å†…,è¿”å›å•ä½çŸ©é˜µ(æ— çº¦æŸ)
                return torch.eye(hidden_dim, device=self.device)
        
        Compute constraint matrix C = I - V @ V^T
        
        Args:
            layer_id: Layer index
            hidden_dim: Hidden dimension size (e.g., 1536)
        
        Returns:
            C: Constraint matrix of shape (hidden_dim, hidden_dim)
        """
        if layer_id not in self.subspaces:
            return torch.eye(hidden_dim, device=self.device)
        
        V = self.subspaces[layer_id]  # Shape: (hidden_dim, subspace_rank)
        I = torch.eye(hidden_dim, device=self.device)
        
        # C = I - V @ V^T, shape: (hidden_dim, hidden_dim)
        C = I - torch.mm(V, V.t())
        
        return C
    
    def apply_constraint_to_lora(self, lora_A, lora_B, layer_id):
        """
        Apply ABC constraint: Delta_W = B @ A @ C
        
        Args:
            lora_A: LoRA A matrix, shape (lora_rank, hidden_dim)
            lora_B: LoRA B matrix, shape (hidden_dim, lora_rank)
            layer_id: Layer index
            
        Returns:
            delta_W: Constrained weight update (hidden_dim, hidden_dim)
        """
        # Get hidden dimension from lora_A
        hidden_dim = lora_A.size(1)
        
        # Compute constraint matrix C
        C = self.compute_constraint_matrix(layer_id, hidden_dim)
        
        # Apply constraint: Delta_W = B @ (A @ C)
        # A: (r, d), C: (d, d) -> A@C: (r, d)
        # B: (d, r), A@C: (r, d) -> B@(A@C): (d, d)
        A_constrained = torch.mm(lora_A, C)
        delta_W = torch.mm(lora_B, A_constrained)
        
        return delta_W


class MultiPositionActivationExtractor:
    """æå–å¤šä¸ª token ä½ç½®çš„æ¿€æ´»å€¼ (å¤ç”¨è®­ç»ƒæ—¶çš„é€»è¾‘)"""
    
    def __init__(self, model, tokenizer, device='cuda:0'):
        self.model = model
        self.tokenizer = tokenizer
        self.device = device
        self.activations = {}
        self.hooks = []
        
        # è·å–æ¨¡å‹é…ç½®
        config = model.config
        self.num_layers = config.num_hidden_layers
        self.hidden_size = config.hidden_size
        self.num_heads = config.num_attention_heads
        self.head_dim = self.hidden_size // self.num_heads
        
        print(f"\nğŸ“Š æ¨¡å‹é…ç½®:")
        print(f"   å±‚æ•°: {self.num_layers}")
        print(f"   éšè—å±‚ç»´åº¦: {self.hidden_size}")
        print(f"   æ³¨æ„åŠ›å¤´æ•°: {self.num_heads}")
        print(f"   æ¯ä¸ªå¤´ç»´åº¦: {self.head_dim}")
    
    def _get_activation_hook(self, layer_id):
        """åˆ›å»º hook å‡½æ•°æ¥æ•è·å®Œæ•´åºåˆ—çš„æ¿€æ´»å€¼"""
        def hook(module, input, output):
            key = f"layer-{layer_id}"
            if key not in self.activations:
                self.activations[key] = []
            # ä¿å­˜å®Œæ•´åºåˆ—: (batch_size, seq_len, hidden_dim)
            self.activations[key].append(output.detach().cpu())
        return hook
    
    def register_hooks(self):
        """æ³¨å†Œ hooks åˆ°æ‰€æœ‰å±‚çš„ Q æŠ•å½±"""
        self.activations = {}
        self.hooks = []
        
        # å…¼å®¹ PeftModel å’ŒåŸºç¡€æ¨¡å‹
        if hasattr(self.model, 'get_base_model'):
            # PeftModel: ä½¿ç”¨ get_base_model() æ–¹æ³•
            base_model = self.model.get_base_model()
            base_layers = base_model.model.layers
        else:
            # åŸºç¡€æ¨¡å‹: model.model.layers
            base_layers = self.model.model.layers
        
        for layer_id in range(self.num_layers):
            layer = base_layers[layer_id]
            hook = layer.self_attn.q_proj.register_forward_hook(
                self._get_activation_hook(layer_id)
            )
            self.hooks.append(hook)
    
    def remove_hooks(self):
        """ç§»é™¤æ‰€æœ‰ hooks"""
        for hook in self.hooks:
            hook.remove()
        self.hooks = []
    
    def find_token_positions(self, text: str, inputs) -> Dict[str, int]:
        """
        å®šä½å…³é”® token ä½ç½®
        
        è¿”å›æ ¼å¼: {
            'user_last': int,
            'assistant_first': int,
            'assistant_last': int,
            'assistant_range': (start, end)
        }
        """
        tokens = self.tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])
        
        positions = {}
        
        # å¯»æ‰¾ assistant æ ‡è®°çš„ä½ç½®
        assistant_markers = ['assistant', '<|assistant|>', 'Assistant']
        assistant_start = -1
        
        for i, token in enumerate(tokens):
            for marker in assistant_markers:
                if marker.lower() in token.lower():
                    assistant_start = i
                    break
            if assistant_start != -1:
                break
        
        # å¦‚æœæ‰¾ä¸åˆ°åŠ©æ‰‹æ ‡è®°,ä½¿ç”¨ç®€å•çš„åˆ†å‰²ç­–ç•¥
        if assistant_start == -1:
            seq_len = len(tokens)
            assistant_start = seq_len // 2
        
        # è®¡ç®—å„ä¸ªä½ç½®
        positions['user_last'] = max(0, assistant_start - 1)
        positions['assistant_first'] = min(assistant_start + 1, len(tokens) - 1)
        positions['assistant_last'] = len(tokens) - 1
        positions['assistant_range'] = (assistant_start + 1, len(tokens))
        
        return positions
    
    def format_conversation(self, prompt, response):
        """æ ¼å¼åŒ–å¯¹è¯ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼"""
        messages = [
            {"role": "user", "content": prompt},
            {"role": "assistant", "content": response}
        ]
        text = self.tokenizer.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=False
        )
        return text
    
    def extract_from_pairs(self, pairs, max_samples=None, 
                          positions=['user_last', 'assistant_first', 'assistant_last', 'assistant_mean']):
        """
        ä»é…å¯¹æ•°æ®ä¸­æå–å¤šä¸ªä½ç½®çš„æ¿€æ´»å€¼
        
        Args:
            pairs: é…å¯¹æ•°æ®åˆ—è¡¨
            max_samples: æœ€å¤§æ ·æœ¬æ•°
            positions: è¦æå–çš„ä½ç½®åˆ—è¡¨
        
        Returns:
            Dict[position_name, Dict[head_key, activations]]
        """
        self.activations = {}
        self.register_hooks()
        
        print(f"ğŸ“¥ æå– {len(pairs)} ä¸ªé…å¯¹çš„æ¿€æ´»å€¼...")
        print(f"ğŸ“ æå–ä½ç½®: {', '.join(positions)}")
        self.model.eval()
        
        if max_samples:
            pairs = pairs[:max_samples]
        
        # å­˜å‚¨æ¯ä¸ªæ ·æœ¬çš„ä½ç½®ä¿¡æ¯
        position_indices = []
        
        with torch.no_grad():
            for pair in tqdm(pairs, desc="æå–æ¿€æ´»"):
                text = self.format_conversation(pair['prompt'], pair['response'])
                inputs = self.tokenizer(
                    text,
                    return_tensors='pt',
                    truncation=True,
                    max_length=512
                ).to(self.device)
                
                # è®°å½•ä½ç½®
                pos_info = self.find_token_positions(text, inputs)
                position_indices.append(pos_info)
                
                self.model(**inputs)
        
        self.remove_hooks()
        
        # æ•´ç†æ¿€æ´»å€¼: æŒ‰ä½ç½®å’Œæ³¨æ„åŠ›å¤´ç»„ç»‡
        print("ğŸ”„ æ•´ç†æ¿€æ´»å€¼...")
        result = {pos: {} for pos in positions}
        
        for layer_id in tqdm(range(self.num_layers), desc="å¤„ç†å±‚"):
            key = f"layer-{layer_id}"
            if key not in self.activations:
                continue
            
            layer_acts_list = self.activations[key]
            
            for head_id in range(self.num_heads):
                start_idx = head_id * self.head_dim
                end_idx = (head_id + 1) * self.head_dim
                head_key = f"layer-{layer_id}-head-{head_id}"
                
                # ä¸ºæ¯ä¸ªä½ç½®æå–æ¿€æ´»
                for pos_name in positions:
                    acts_for_position = []
                    
                    for sample_idx, (act_tensor, pos_info) in enumerate(zip(layer_acts_list, position_indices)):
                        # act_tensor: (1, seq_len, hidden_dim)
                        act = act_tensor[0, :, start_idx:end_idx].numpy()  # (seq_len, head_dim)
                        
                        if pos_name == 'user_last':
                            token_idx = pos_info['user_last']
                            acts_for_position.append(act[token_idx])
                        
                        elif pos_name == 'assistant_first':
                            token_idx = pos_info['assistant_first']
                            acts_for_position.append(act[token_idx])
                        
                        elif pos_name == 'assistant_last':
                            token_idx = pos_info['assistant_last']
                            acts_for_position.append(act[token_idx])
                        
                        elif pos_name == 'assistant_mean':
                            start, end = pos_info['assistant_range']
                            mean_act = act[start:end].mean(axis=0)
                            acts_for_position.append(mean_act)
                    
                    result[pos_name][head_key] = np.array(acts_for_position)
        
        print(f"âœ… æå–å®Œæˆ! æ¯ä¸ªä½ç½®å…± {len(result[positions[0]])} ä¸ªæ³¨æ„åŠ›å¤´")
        return result


def load_model_with_abc(model_path, lora_path, subspace_dir, dimension, device='cuda:0', constrained_layers=None):
    """Load model and apply ABC constraints"""
    print(f"\n Loading model with ABC constraints...")
    print(f"   Base model: {model_path}")
    print(f"   LoRA: {lora_path}")
    print(f"   Subspace dir: {subspace_dir}")
    print(f"   Dimension: {dimension}")
    
    tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
    
    print(f"\n Loading base model...")
    model = AutoModelForCausalLM.from_pretrained(
        model_path,
        torch_dtype=torch.float16,
        device_map=device,
        trust_remote_code=True
    )
    
    # Load ABC constraints
    abc_loader = ABCConstraintLoader(subspace_dir, dimension, device, constrained_layers)
    has_constraints = abc_loader.load_subspaces()
    
    # æ‰“å°å±‚çº¦æŸä¿¡æ¯
    if constrained_layers is not None:
        print(f"   ğŸ¯ Constrained layers: {constrained_layers[0]}-{constrained_layers[1]}")
    else:
        print(f"   ğŸ¯ Constrained layers: All layers (0-27)")
    
    # Manually load LoRA and apply ABC
    print(f"\n Loading LoRA weights and applying ABC constraints...")
    
    # å°è¯•åŠ è½½ safetensors æˆ– bin æ ¼å¼
    adapter_file_st = os.path.join(lora_path, 'adapter_model.safetensors')
    adapter_file_bin = os.path.join(lora_path, 'adapter_model.bin')
    
    if os.path.exists(adapter_file_st):
        print(f"   Loading adapter from: adapter_model.safetensors")
        from safetensors.torch import load_file
        lora_state_dict = load_file(adapter_file_st)
    elif os.path.exists(adapter_file_bin):
        print(f"   Loading adapter from: adapter_model.bin")
        lora_state_dict = torch.load(adapter_file_bin, map_location='cpu', weights_only=False)
    else:
        raise FileNotFoundError(f"No adapter found at {lora_path}. Expected adapter_model.safetensors or adapter_model.bin")
    
    with open(os.path.join(lora_path, 'adapter_config.json'), 'r') as f:
        lora_config = json.load(f)
    
    lora_r = lora_config['r']
    lora_alpha = lora_config['lora_alpha']
    scaling = lora_alpha / lora_r
    
    print(f"   LoRA config: r={lora_r}, alpha={lora_alpha}, scaling={scaling}")
    
    # Merge layer by layer
    merge_count = 0
    skip_count = 0
    base_layers = model.model.layers
    
    for layer_id in tqdm(range(len(base_layers)), desc="Merging LoRA+ABC"):
        layer = base_layers[layer_id]
        
        q_lora_A_key = f"base_model.model.model.layers.{layer_id}.self_attn.q_proj.lora_A.weight"
        q_lora_B_key = f"base_model.model.model.layers.{layer_id}.self_attn.q_proj.lora_B.weight"
        
        if q_lora_A_key in lora_state_dict and q_lora_B_key in lora_state_dict:
            lora_A = lora_state_dict[q_lora_A_key].to(device)
            lora_B = lora_state_dict[q_lora_B_key].to(device)
            
            if has_constraints:
                delta_W = abc_loader.apply_constraint_to_lora(lora_A, lora_B, layer_id)
            else:
                delta_W = torch.mm(lora_B, lora_A)
            
            with torch.no_grad():
                layer.self_attn.q_proj.weight.data += scaling * delta_W.to(torch.float16)
            
            merge_count += 1
        else:
            skip_count += 1
    
    print(f"\n LoRA+ABC merge complete: {merge_count} merged, {skip_count} skipped")
    
    model_type = "lora_with_abc" if has_constraints else "lora_only"
    return model, tokenizer, model_type



def load_position_probes(probe_dir, position, dimension):
    """
    åŠ è½½æŒ‡å®šä½ç½®çš„æ¢é’ˆ
    
    Args:
        probe_dir: æ¢é’ˆæ ¹ç›®å½•
        position: ä½ç½®åç§° (å¦‚ assistant_last)
        dimension: ç»´åº¦åç§° (å¦‚ safety)
        
    Returns:
        dict: {head_key: LogisticRegressionæ¨¡å‹}
    """
    # æ„å»ºæ¢é’ˆæ–‡ä»¶è·¯å¾„: {dimension}_{position}_probes/
    probe_subdir = os.path.join(probe_dir, f"{dimension}_{position}_probes")
    
    if not os.path.exists(probe_subdir):
        raise FileNotFoundError(f"æ¢é’ˆç›®å½•ä¸å­˜åœ¨: {probe_subdir}")
    
    print(f"\nğŸ“‚ åŠ è½½æ¢é’ˆ [{position}]...")
    print(f"   æ¢é’ˆç›®å½•: {probe_subdir}")
    
    # åŠ è½½æ‰€æœ‰æ¢é’ˆæ–‡ä»¶
    probes = {}
    probe_files = sorted([f for f in os.listdir(probe_subdir) if f.endswith('.pkl')])
    
    for probe_file in probe_files:
        # æ–‡ä»¶åæ ¼å¼: layer-{layer_id}-head-{head_id}.pkl
        probe_path = os.path.join(probe_subdir, probe_file)
        with open(probe_path, 'rb') as f:
            probe = pickle.load(f)
        
        # æå– key: layer-{layer_id}-head-{head_id}
        key = probe_file.replace('.pkl', '')
        probes[key] = probe
    
    print(f"   âœ… å·²åŠ è½½ {len(probes)} ä¸ªæ¢é’ˆ")
    
    return probes


def load_test_data(test_data_dir, dimension):
    """åŠ è½½æµ‹è¯•æ•°æ®"""
    good_file = os.path.join(test_data_dir, f"{dimension}_good_pairs.json")
    bad_file = os.path.join(test_data_dir, f"{dimension}_bad_pairs.json")
    
    # å°è¯•å…¶ä»–å¯èƒ½çš„æ–‡ä»¶å
    if not os.path.exists(good_file):
        good_file = os.path.join(test_data_dir, "safe_pairs_large.json")
    if not os.path.exists(bad_file):
        bad_file = os.path.join(test_data_dir, "harmful_pairs_large.json")
    
    print(f"\nğŸ“‚ åŠ è½½æµ‹è¯•æ•°æ®...")
    print(f"   å¥½æ ·æœ¬: {good_file}")
    print(f"   åæ ·æœ¬: {bad_file}")
    
    with open(good_file, 'r', encoding='utf-8') as f:
        good_samples = json.load(f)
    
    with open(bad_file, 'r', encoding='utf-8') as f:
        bad_samples = json.load(f)
    
    print(f"   âœ… å¥½æ ·æœ¬æ•°: {len(good_samples)}")
    print(f"   âœ… åæ ·æœ¬æ•°: {len(bad_samples)}")
    
    return good_samples, bad_samples


def evaluate_position_probes(probes, good_activations, bad_activations):
    """
    è¯„ä¼°æŒ‡å®šä½ç½®çš„æ¢é’ˆæ€§èƒ½
    
    Args:
        probes: {head_key: probe_model}
        good_activations: {head_key: np.array}
        bad_activations: {head_key: np.array}
    
    Returns:
        results: {head_key: metrics_dict}
    """
    results = {}
    
    for head_key in tqdm(probes.keys(), desc="è¯„ä¼°æ¢é’ˆ"):
        if head_key not in good_activations or head_key not in bad_activations:
            continue
        
        probe = probes[head_key]
        
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        X_good = good_activations[head_key]
        X_bad = bad_activations[head_key]
        
        X_test = np.vstack([X_good, X_bad])
        y_test = np.array([1] * len(X_good) + [0] * len(X_bad))
        
        # é¢„æµ‹
        y_pred = probe.predict(X_test)
        
        # è®¡ç®—æŒ‡æ ‡
        accuracy = accuracy_score(y_test, y_pred)
        precision, recall, f1, _ = precision_recall_fscore_support(
            y_test, y_pred, average='binary', zero_division=0
        )
        
        results[head_key] = {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1': f1,
            'n_samples': len(y_test)
        }
    
    return results


def print_position_summary(position, results):
    """æ‰“å°å•ä¸ªä½ç½®çš„ç»Ÿè®¡æ‘˜è¦"""
    accuracies = [r['accuracy'] for r in results.values()]
    f1_scores = [r['f1'] for r in results.values()]
    
    print(f"\n{'='*80}")
    print(f"ğŸ“ ä½ç½®: {position}")
    print(f"{'='*80}")
    print(f"æ¢é’ˆæ•°é‡: {len(results)}")
    print(f"å¹³å‡å‡†ç¡®ç‡: {np.mean(accuracies):.4f} Â± {np.std(accuracies):.4f}")
    print(f"å¹³å‡ F1: {np.mean(f1_scores):.4f} Â± {np.std(f1_scores):.4f}")
    print(f"æœ€é«˜å‡†ç¡®ç‡: {np.max(accuracies):.4f}")
    print(f"æœ€ä½å‡†ç¡®ç‡: {np.min(accuracies):.4f}")
    print(f"å‡†ç¡®ç‡ >= 0.8: {sum(1 for a in accuracies if a >= 0.8)}")
    print(f"å‡†ç¡®ç‡ >= 0.9: {sum(1 for a in accuracies if a >= 0.9)}")


def save_results(output_dir, dimension, model_type, all_position_results):
    """ä¿å­˜æµ‹è¯•ç»“æœ"""
    os.makedirs(output_dir, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # ä¿å­˜è¯¦ç»†ç»“æœ (JSON)
    results_file = os.path.join(
        output_dir, 
        f"{dimension}_{model_type}_multi_position_test_{timestamp}.json"
    )
    
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(all_position_results, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜:")
    print(f"   {results_file}")
    
    # ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š
    report_file = os.path.join(
        output_dir,
        f"{dimension}_{model_type}_multi_position_report_{timestamp}.txt"
    )
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("="*80 + "\n")
        f.write(f"å¤šä½ç½®æ¢é’ˆæµ‹è¯•æŠ¥å‘Š\n")
        f.write("="*80 + "\n")
        f.write(f"ç»´åº¦: {dimension}\n")
        f.write(f"æ¨¡å‹ç±»å‹: {model_type}\n")
        f.write(f"æµ‹è¯•æ—¶é—´: {timestamp}\n")
        f.write("="*80 + "\n\n")
        
        # ä½ç½®å¯¹æ¯”æ±‡æ€»
        f.write("ğŸ“Š ä½ç½®æ€§èƒ½å¯¹æ¯”\n")
        f.write("-"*80 + "\n")
        
        position_summary = {}
        for pos_name, pos_results in all_position_results.items():
            accuracies = [r['accuracy'] for r in pos_results.values()]
            position_summary[pos_name] = {
                'mean_acc': np.mean(accuracies),
                'std_acc': np.std(accuracies),
                'max_acc': np.max(accuracies),
                'count_80': sum(1 for a in accuracies if a >= 0.8),
                'count_90': sum(1 for a in accuracies if a >= 0.9)
            }
        
        # æŒ‰å¹³å‡å‡†ç¡®ç‡æ’åº
        sorted_positions = sorted(
            position_summary.items(),
            key=lambda x: x[1]['mean_acc'],
            reverse=True
        )
        
        for pos_name, summary in sorted_positions:
            f.write(f"\nğŸ“ {pos_name}\n")
            f.write(f"   å¹³å‡å‡†ç¡®ç‡: {summary['mean_acc']:.4f} Â± {summary['std_acc']:.4f}\n")
            f.write(f"   æœ€é«˜å‡†ç¡®ç‡: {summary['max_acc']:.4f}\n")
            f.write(f"   å‡†ç¡®ç‡>=0.8: {summary['count_80']}\n")
            f.write(f"   å‡†ç¡®ç‡>=0.9: {summary['count_90']}\n")
        
        # è¯¦ç»†çš„æ¯å±‚ç»“æœ
        f.write("\n\n" + "="*80 + "\n")
        f.write("ğŸ“Š è¯¦ç»†çš„æ¯å±‚ç»“æœ\n")
        f.write("="*80 + "\n")
        
        for pos_name, pos_results in all_position_results.items():
            f.write(f"\n\n{'='*80}\n")
            f.write(f"ä½ç½®: {pos_name}\n")
            f.write(f"{'='*80}\n")
            
            # æŒ‰layeræ’åº
            sorted_heads = sorted(pos_results.keys())
            for head_key in sorted_heads:
                metrics = pos_results[head_key]
                f.write(f"\n{head_key}:\n")
                f.write(f"  å‡†ç¡®ç‡: {metrics['accuracy']:.4f}\n")
                f.write(f"  ç²¾ç¡®ç‡: {metrics['precision']:.4f}\n")
                f.write(f"  å¬å›ç‡: {metrics['recall']:.4f}\n")
                f.write(f"  F1åˆ†æ•°: {metrics['f1']:.4f}\n")
    
    print(f"   {report_file}")


def main():
    parser = argparse.ArgumentParser(description='å¤šä½ç½®æ¢é’ˆå‡†ç¡®åº¦æµ‹è¯•')
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--model_path', type=str, required=True, 
                       help='åŸºç¡€æ¨¡å‹è·¯å¾„')
    parser.add_argument('--lora_path', type=str, required=True,
                       help='LoRA adapter path')
    parser.add_argument('--subspace_dir', type=str,
                       default='preference_subspace/saved_subspaces',
                       help='Subspace directory')
    parser.add_argument('--constrained_layers', type=str, default=None,
                       help='çº¦æŸå±‚èŒƒå›´,æ ¼å¼: "start,end" (å¦‚ "0,8" æˆ– "16,16"), Noneè¡¨ç¤ºæ‰€æœ‰å±‚')
    parser.add_argument('--device', type=str, default='cuda:0',
                       help='è®¡ç®—è®¾å¤‡')
    
    # æ¢é’ˆå‚æ•°
    parser.add_argument('--probe_dir', type=str, required=True,
                       help='æ¢é’ˆæ ¹ç›®å½• (åŒ…å«å¤šä¸ªä½ç½®çš„æ¢é’ˆ)')
    parser.add_argument('--positions', type=str, nargs='+',
                       default=['assistant_last'],
                       choices=['user_last', 'assistant_first', 'assistant_last', 'assistant_mean'],
                       help='è¦æµ‹è¯•çš„ä½ç½®åˆ—è¡¨')
    
    # æ•°æ®å‚æ•°
    parser.add_argument('--test_data', type=str, required=True,
                       help='æµ‹è¯•æ•°æ®ç›®å½•')
    parser.add_argument('--dimension', type=str, required=True,
                       help='æµ‹è¯•ç»´åº¦ (å¦‚ safety, helpfulness)')
    parser.add_argument('--max_samples', type=int, default=None,
                       help='æœ€å¤§æµ‹è¯•æ ·æœ¬æ•°')
    
    # è¾“å‡ºå‚æ•°
    parser.add_argument('--output_dir', type=str, default='results',
                       help='ç»“æœè¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    print("\n" + "="*80)
    print("ğŸ§ª å¤šä½ç½®æ¢é’ˆå‡†ç¡®åº¦æµ‹è¯•")
    print("="*80)
    print(f"ğŸ“Š ç»´åº¦: {args.dimension}")
    print(f"ğŸ“ æµ‹è¯•ä½ç½®: {', '.join(args.positions)}")
    print(f"ğŸ“ æ¢é’ˆç›®å½•: {args.probe_dir}")
    print(f"ğŸ“ æµ‹è¯•æ•°æ®: {args.test_data}")
    if args.max_samples:
        print(f"ğŸ“¦ æµ‹è¯•æ ·æœ¬æ•°: {args.max_samples}")
    print("="*80)
    
    # 1. åŠ è½½æ¨¡å‹
    # è§£æå±‚çº¦æŸå‚æ•°
    constrained_layers = None
    if args.constrained_layers:
        start, end = map(int, args.constrained_layers.split(','))
        constrained_layers = (start, end)
        print(f"ğŸ¯ å°†çº¦æŸåº”ç”¨äºå±‚: {start}-{end}")
    else:
        print(f"ğŸ¯ å°†çº¦æŸåº”ç”¨äºæ‰€æœ‰å±‚")
    
    model, tokenizer, model_type = load_model_with_abc(
        args.model_path,
        args.lora_path,
        args.subspace_dir,
        args.dimension,
        args.device,
        constrained_layers
    )
    
    # 2. åŠ è½½æµ‹è¯•æ•°æ®
    good_samples, bad_samples = load_test_data(args.test_data, args.dimension)
    
    # 3. åˆ›å»ºæ¿€æ´»æå–å™¨
    extractor = MultiPositionActivationExtractor(model, tokenizer, args.device)
    
    # 4. æå–å¤šä½ç½®æ¿€æ´»
    print(f"\n{'='*80}")
    print("ğŸ” æå–æ¿€æ´»å€¼ (æ‰€æœ‰ä½ç½®)")
    print(f"{'='*80}")
    
    good_acts_multi = extractor.extract_from_pairs(
        good_samples,
        args.max_samples,
        args.positions
    )
    
    bad_acts_multi = extractor.extract_from_pairs(
        bad_samples,
        args.max_samples,
        args.positions
    )
    
    # 5. ä¸ºæ¯ä¸ªä½ç½®åŠ è½½æ¢é’ˆå¹¶æµ‹è¯•
    all_position_results = {}
    
    for position in args.positions:
        print(f"\n{'='*80}")
        print(f"ğŸ§ª æµ‹è¯•ä½ç½®: {position}")
        print(f"{'='*80}")
        
        # åŠ è½½è¯¥ä½ç½®çš„æ¢é’ˆ
        try:
            probes = load_position_probes(args.probe_dir, position, args.dimension)
        except FileNotFoundError as e:
            print(f"âš ï¸  è·³è¿‡ä½ç½® {position}: {e}")
            continue
        
        # è¯„ä¼°è¯¥ä½ç½®çš„æ¢é’ˆ
        position_results = evaluate_position_probes(
            probes,
            good_acts_multi[position],
            bad_acts_multi[position]
        )
        
        all_position_results[position] = position_results
        
        # æ‰“å°è¯¥ä½ç½®çš„ç»Ÿè®¡æ‘˜è¦
        print_position_summary(position, position_results)
    
    # 6. ä¿å­˜ç»“æœ
    if all_position_results:
        save_results(args.output_dir, args.dimension, model_type, all_position_results)
        
        print(f"\n{'='*80}")
        print("âœ… æµ‹è¯•å®Œæˆ!")
        print(f"{'='*80}")
    else:
        print(f"\nâš ï¸  æ²¡æœ‰æˆåŠŸæµ‹è¯•ä»»ä½•ä½ç½®")


if __name__ == '__main__':
    main()
