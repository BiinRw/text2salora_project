"""
åå¥½å­ç©ºé—´ SVD åˆ†è§£ (æ”¯æŒæŠ•å½±å±‚ç‰¹å®šæ–‡ä»¶)
å¯¹ç‰¹å¾å·®åˆ†æ‰§è¡Œå¥‡å¼‚å€¼åˆ†è§£,æå–åå¥½å­ç©ºé—´åŸºå‘é‡
v2: æ”¯æŒè¯»å– {dimension}_{projection}_feature_diff.npz æ ¼å¼æ–‡ä»¶
"""

import os
import json
import torch
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional
import matplotlib.pyplot as plt


def load_feature_diff(feature_file: str) -> Dict[int, np.ndarray]:
    """åŠ è½½ç‰¹å¾å·®åˆ†æ–‡ä»¶
    
    Args:
        feature_file: ç‰¹å¾å·®åˆ†æ–‡ä»¶è·¯å¾„
        
    Returns:
        layer_diffs: {layer_id: diff_array}
    """
    print(f"ğŸ“‚ åŠ è½½ç‰¹å¾å·®åˆ†: {feature_file}")
    data = np.load(feature_file)
    
    layer_diffs = {}
    
    # æ£€æŸ¥æ˜¯å¦æœ‰num_layerså­—æ®µ
    if 'num_layers' in data:
        num_layers = int(data['num_layers'])
    else:
        # æ—§ç‰ˆæœ¬æ–‡ä»¶,å°è¯•æŸ¥æ‰¾æ‰€æœ‰layer_*é”®
        layer_keys = [k for k in data.keys() if k.startswith('layer_')]
        num_layers = len(layer_keys)
    
    for layer_id in range(num_layers):
        key = f'layer_{layer_id}'
        if key in data:
            layer_diffs[layer_id] = data[key]
    
    print(f"   âœ… åŠ è½½ {len(layer_diffs)} å±‚çš„ç‰¹å¾å·®åˆ†")
    if 'num_samples' in data:
        print(f"   æ ·æœ¬æ•°: {data['num_samples']}")
    if 'hidden_size' in data:
        print(f"   è¾“å‡ºç»´åº¦: {data['hidden_size']}")
    
    return layer_diffs


def compute_svd_for_layer(
    diff: np.ndarray,
    top_k: int = 64,
    device: str = 'cuda:0'
) -> Dict:
    """å¯¹å•å±‚çš„ç‰¹å¾å·®åˆ†æ‰§è¡Œ SVD åˆ†è§£
    
    Args:
        diff: ç‰¹å¾å·®åˆ†çŸ©é˜µ (N, d)
        top_k: ä¿ç•™çš„å¥‡å¼‚å‘é‡æ•°é‡
        device: è®¡ç®—è®¾å¤‡
        
    Returns:
        subspace_dict: {U, S, V, explained_variance_ratio}
    """
    # è½¬æ¢ä¸º tensor
    diff_tensor = torch.from_numpy(diff).float().to(device)
    
    # SVD åˆ†è§£
    U, S, V = torch.svd_lowrank(diff_tensor, q=top_k, niter=2)
    
    # è®¡ç®—æ–¹å·®è§£é‡Šç‡
    total_variance = torch.sum(S ** 2)
    explained_variance = torch.cumsum(S ** 2, dim=0) / total_variance
    
    return {
        'U': U.cpu(),  # (N, top_k)
        'S': S.cpu(),  # (top_k,)
        'V': V.cpu(),  # (d, top_k) - è¿™æ˜¯åå¥½å­ç©ºé—´çš„åŸºå‘é‡!
        'explained_variance_ratio': explained_variance.cpu(),
        'total_variance': total_variance.cpu().item()
    }


def compute_multi_layer_svd(
    layer_diffs: Dict[int, np.ndarray],
    top_k: int = 64,
    device: str = 'cuda:0',
    layer_selection: Optional[List[int]] = None
) -> Dict[int, Dict]:
    """å¯¹å¤šå±‚æ‰§è¡Œ SVD åˆ†è§£
    
    Args:
        layer_diffs: {layer_id: diff_array}
        top_k: ä¿ç•™çš„å¥‡å¼‚å‘é‡æ•°é‡
        device: è®¾å¤‡
        layer_selection: é€‰æ‹©ç‰¹å®šå±‚ (None=æ‰€æœ‰å±‚)
        
    Returns:
        layer_subspaces: {layer_id: subspace_dict}
    """
    if layer_selection is None:
        layer_selection = sorted(layer_diffs.keys())
    
    print(f"\nğŸ”¬ å¯¹ {len(layer_selection)} å±‚æ‰§è¡Œ SVD åˆ†è§£ (top_k={top_k})")
    
    layer_subspaces = {}
    
    for layer_id in layer_selection:
        if layer_id not in layer_diffs:
            print(f"   âš ï¸  Layer {layer_id} ä¸å­˜åœ¨,è·³è¿‡")
            continue
        
        diff = layer_diffs[layer_id]
        print(f"\n   Layer {layer_id:2d}: shape={diff.shape}")
        
        subspace = compute_svd_for_layer(diff, top_k, device)
        layer_subspaces[layer_id] = subspace
        
        # æ‰“å°æ–¹å·®è§£é‡Šç‡
        ev_ratio = subspace['explained_variance_ratio']
        print(f"      Top 10 å¥‡å¼‚å€¼è§£é‡Šæ–¹å·®: {ev_ratio[9].item():.4f}")
        print(f"      Top 32 å¥‡å¼‚å€¼è§£é‡Šæ–¹å·®: {ev_ratio[31].item():.4f}")
        if len(ev_ratio) >= 64:
            print(f"      Top 64 å¥‡å¼‚å€¼è§£é‡Šæ–¹å·®: {ev_ratio[-1].item():.4f}")
    
    return layer_subspaces


def fuse_multi_layer_subspace(
    layer_subspaces: Dict[int, Dict],
    method: str = 'weighted_avg',
    weights: Optional[Dict[int, float]] = None
) -> Dict:
    """èåˆå¤šå±‚å­ç©ºé—´
    
    Args:
        layer_subspaces: {layer_id: subspace_dict}
        method: èåˆæ–¹æ³• ('weighted_avg', 'concat', 'avg')
        weights: å±‚æƒé‡ {layer_id: weight} (ç”¨äº weighted_avg)
        
    Returns:
        fused_subspace: èåˆåçš„å­ç©ºé—´
    """
    if method == 'concat':
        # æ‹¼æ¥å¤šå±‚çš„ V çŸ©é˜µ
        V_list = [subspace['V'] for subspace in layer_subspaces.values()]
        V_fused = torch.cat(V_list, dim=1)  # (d, num_layers * top_k)
        
        return {
            'V': V_fused,
            'method': 'concat',
            'num_layers': len(layer_subspaces)
        }
    
    elif method == 'weighted_avg':
        # åŠ æƒå¹³å‡
        if weights is None:
            # ä½¿ç”¨å¥‡å¼‚å€¼ä½œä¸ºæƒé‡
            weights = {
                layer_id: subspace['S'][0].item()
                for layer_id, subspace in layer_subspaces.items()
            }
        
        # å½’ä¸€åŒ–æƒé‡
        total_weight = sum(weights.values())
        weights = {k: v/total_weight for k, v in weights.items()}
        
        # åŠ æƒå¹³å‡ V çŸ©é˜µ
        V_fused = None
        for layer_id, subspace in layer_subspaces.items():
            if V_fused is None:
                V_fused = weights[layer_id] * subspace['V']
            else:
                V_fused += weights[layer_id] * subspace['V']
        
        return {
            'V': V_fused,
            'method': 'weighted_avg',
            'weights': weights
        }
    
    elif method == 'avg':
        # ç®€å•å¹³å‡
        V_list = [subspace['V'] for subspace in layer_subspaces.values()]
        V_fused = torch.stack(V_list).mean(dim=0)
        
        return {
            'V': V_fused,
            'method': 'avg',
            'num_layers': len(layer_subspaces)
        }
    
    else:
        raise ValueError(f"Unknown fusion method: {method}")


def save_subspaces(
    layer_subspaces: Dict[int, Dict],
    dimension: str,
    projection_type: str,  # æ–°å¢: æŠ•å½±å±‚ç±»å‹
    output_dir: str,
    fused_subspace: Optional[Dict] = None
):
    """ä¿å­˜å­ç©ºé—´åˆ°æ–‡ä»¶
    
    Args:
        layer_subspaces: {layer_id: subspace_dict}
        dimension: åå¥½ç»´åº¦åç§°
        projection_type: æŠ•å½±å±‚ç±»å‹
        output_dir: è¾“å‡ºç›®å½•
        fused_subspace: èåˆåçš„å­ç©ºé—´ (å¯é€‰)
    """
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜å„å±‚å­ç©ºé—´ (æ–‡ä»¶ååŒ…å«projection)
    for layer_id, subspace in layer_subspaces.items():
        filename = output_dir / f'{dimension}_{projection_type}_layer{layer_id}_subspace.pt'
        torch.save({
            'V': subspace['V'],
            'S': subspace['S'],
            'U': subspace['U'],
            'explained_variance_ratio': subspace['explained_variance_ratio'],
            'layer_id': layer_id,
            'dimension': dimension,
            'projection': projection_type  # æ–°å¢: ä¿å­˜æŠ•å½±ç±»å‹ä¿¡æ¯
        }, filename)
        print(f"   âœ… ä¿å­˜: {filename.name}")
    
    # ä¿å­˜èåˆå­ç©ºé—´
    if fused_subspace is not None:
        filename = output_dir / f'{dimension}_{projection_type}_fused_subspace.pt'
        torch.save({
            'V': fused_subspace['V'],
            'method': fused_subspace['method'],
            'dimension': dimension,
            'projection': projection_type,  # æ–°å¢
            **{k: v for k, v in fused_subspace.items() if k not in ['V', 'method']}
        }, filename)
        print(f"   âœ… ä¿å­˜èåˆå­ç©ºé—´: {filename.name}")
    
    # ä¿å­˜å…ƒä¿¡æ¯
    meta_file = output_dir / f'{dimension}_{projection_type}_meta.json'
    meta_info = {
        'dimension': dimension,
        'projection': projection_type,  # æ–°å¢
        'num_layers': len(layer_subspaces),
        'layer_ids': sorted(layer_subspaces.keys()),
        'subspace_rank': layer_subspaces[list(layer_subspaces.keys())[0]]['V'].shape[1],
        'fused': fused_subspace is not None,
        'fuse_method': fused_subspace['method'] if fused_subspace else None
    }
    with open(meta_file, 'w') as f:
        json.dump(meta_info, f, indent=2)
    print(f"   âœ… ä¿å­˜å…ƒä¿¡æ¯: {meta_file.name}")


def plot_singular_values(
    layer_subspaces: Dict[int, Dict],
    dimension: str,
    projection_type: str,  # æ–°å¢
    output_dir: str
):
    """ç»˜åˆ¶å¥‡å¼‚å€¼åˆ†å¸ƒ"""
    output_dir = Path(output_dir)
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    axes = axes.flatten()
    
    # 1. æ‰€æœ‰å±‚çš„å¥‡å¼‚å€¼
    ax = axes[0]
    for layer_id, subspace in layer_subspaces.items():
        S = subspace['S'].numpy()
        ax.plot(S, alpha=0.5, label=f'Layer {layer_id}')
    ax.set_xlabel('Rank')
    ax.set_ylabel('Singular Value')
    ax.set_title(f'{dimension.capitalize()} - {projection_type} - Singular Values')
    ax.set_yscale('log')
    ax.grid(True, alpha=0.3)
    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)
    
    # 2. æ–¹å·®è§£é‡Šç‡
    ax = axes[1]
    for layer_id, subspace in layer_subspaces.items():
        ev_ratio = subspace['explained_variance_ratio'].numpy()
        ax.plot(ev_ratio, alpha=0.5, label=f'Layer {layer_id}')
    ax.set_xlabel('Number of Components')
    ax.set_ylabel('Cumulative Explained Variance Ratio')
    ax.set_title(f'{dimension.capitalize()} - {projection_type} - Explained Variance')
    ax.grid(True, alpha=0.3)
    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)
    
    # 3. å±‚å¹³å‡å¥‡å¼‚å€¼
    ax = axes[2]
    layer_ids = sorted(layer_subspaces.keys())
    mean_sv = [layer_subspaces[lid]['S'].mean().item() for lid in layer_ids]
    ax.bar(layer_ids, mean_sv)
    ax.set_xlabel('Layer ID')
    ax.set_ylabel('Mean Singular Value')
    ax.set_title(f'{dimension.capitalize()} - {projection_type} - Mean SV per Layer')
    ax.grid(True, alpha=0.3, axis='y')
    
    # 4. Top-k æ–¹å·®è§£é‡Šç‡çƒ­å›¾
    ax = axes[3]
    k_values = [10, 32, 64]
    ev_matrix = []
    for lid in layer_ids:
        ev_ratio = layer_subspaces[lid]['explained_variance_ratio'].numpy()
        ev_at_k = [ev_ratio[k-1] if k <= len(ev_ratio) else ev_ratio[-1] for k in k_values]
        ev_matrix.append(ev_at_k)
    
    im = ax.imshow(np.array(ev_matrix).T, aspect='auto', cmap='viridis')
    ax.set_xticks(range(len(layer_ids)))
    ax.set_xticklabels(layer_ids)
    ax.set_yticks(range(len(k_values)))
    ax.set_yticklabels([f'Top-{k}' for k in k_values])
    ax.set_xlabel('Layer ID')
    ax.set_title(f'{dimension.capitalize()} - {projection_type} - Explained Variance at Top-k')
    plt.colorbar(im, ax=ax)
    
    plt.tight_layout()
    
    output_file = output_dir / f'{dimension}_{projection_type}_singular_values.png'
    plt.savefig(output_file, dpi=150, bbox_inches='tight')
    print(f"   âœ… ä¿å­˜å¯è§†åŒ–: {output_file.name}")
    plt.close()


if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='è®¡ç®—åå¥½å­ç©ºé—´ SVD (æ”¯æŒæŠ•å½±å±‚)')
    parser.add_argument('--feature_file', type=str, required=True,
                        help='ç‰¹å¾å·®åˆ†æ–‡ä»¶è·¯å¾„ ({dimension}_{projection}_feature_diff.npz)')
    parser.add_argument('--dimension', type=str, required=True,
                        help='åå¥½ç»´åº¦åç§°')
    parser.add_argument('--projection', type=str, required=True,
                        help='æŠ•å½±å±‚ç±»å‹ (q_proj/k_proj/v_proj/o_proj/up_proj/down_proj)')
    parser.add_argument('--output_dir', type=str, required=True,
                        help='è¾“å‡ºç›®å½•')
    parser.add_argument('--top_k', type=int, default=64,
                        help='ä¿ç•™çš„å¥‡å¼‚å‘é‡æ•°é‡')
    parser.add_argument('--layers', type=str, default=None,
                        help='é€‰æ‹©ç‰¹å®šå±‚,é€—å·åˆ†éš” (å¦‚: 15,16,17,18)')
    parser.add_argument('--fuse_method', type=str, default='weighted_avg',
                        choices=['weighted_avg', 'concat', 'avg', 'none'],
                        help='å¤šå±‚èåˆæ–¹æ³•')
    parser.add_argument('--device', type=str, default='cuda:0',
                        help='è®¡ç®—è®¾å¤‡')
    
    args = parser.parse_args()
    
    print("=" * 80)
    print(f"ğŸ”¬ è®¡ç®— {args.dimension} ç»´åº¦ - {args.projection} æŠ•å½±çš„åå¥½å­ç©ºé—´")
    print("=" * 80)
    
    # 1. åŠ è½½ç‰¹å¾å·®åˆ†
    layer_diffs = load_feature_diff(args.feature_file)
    
    # 2. é€‰æ‹©å±‚
    if args.layers:
        layer_selection = [int(x) for x in args.layers.split(',')]
        print(f"\nğŸ“Œ é€‰æ‹©å±‚: {layer_selection}")
    else:
        layer_selection = None
        print(f"\nğŸ“Œ ä½¿ç”¨æ‰€æœ‰å±‚")
    
    # 3. è®¡ç®— SVD
    layer_subspaces = compute_multi_layer_svd(
        layer_diffs,
        top_k=args.top_k,
        device=args.device,
        layer_selection=layer_selection
    )
    
    # 4. èåˆå­ç©ºé—´
    fused_subspace = None
    if args.fuse_method != 'none':
        print(f"\nğŸ”— èåˆå¤šå±‚å­ç©ºé—´ (æ–¹æ³•: {args.fuse_method})")
        fused_subspace = fuse_multi_layer_subspace(
            layer_subspaces,
            method=args.fuse_method
        )
        print(f"   âœ… èåˆåå½¢çŠ¶: {fused_subspace['V'].shape}")
    
    # 5. ä¿å­˜
    print(f"\nğŸ’¾ ä¿å­˜å­ç©ºé—´:")
    save_subspaces(
        layer_subspaces,
        args.dimension,
        args.projection,  # æ–°å¢
        args.output_dir,
        fused_subspace
    )
    
    # 6. å¯è§†åŒ–
    print(f"\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–:")
    plot_singular_values(
        layer_subspaces,
        args.dimension,
        args.projection,  # æ–°å¢
        args.output_dir
    )
    
    print("\n" + "=" * 80)
    print("âœ… å®Œæˆ!")
    print("=" * 80)