"""
æ•´åˆ HelpSteer å’Œ HelpSteer2 æ•°æ®é›† (é…å¯¹ç­–ç•¥)

æ­£ç¡®ç­–ç•¥:
1. å¯¹äºæ¯ä¸ªç»´åº¦,æŒ‰ prompt åˆ†ç»„
2. å¯¹äºåŒä¸€ä¸ª prompt:
   - æ‰¾åˆ°æ‰€æœ‰ 4åˆ† çš„å“åº” (Good)
   - æ‰¾åˆ°æ‰€æœ‰ 0åˆ† çš„å“åº” (Bad)
   - å¦‚æœä¸¤è€…éƒ½å­˜åœ¨,åˆ™é…å¯¹
3. è¿™æ ·ç¡®ä¿ Good å’Œ Bad æ˜¯å¯¹åŒä¸€ä¸ªé—®é¢˜çš„ä¸åŒè´¨é‡å“åº”
"""

import json
from datasets import load_dataset
from pathlib import Path
from collections import defaultdict, Counter

def build_paired_extreme_data(dataset, dataset_name):
    """
    ä»æ•°æ®é›†ä¸­æ„å»ºé…å¯¹çš„æç«¯æ•°æ®
    
    ç­–ç•¥: å¯¹äºåŒä¸€ä¸ª prompt,æ‰¾åˆ° 4åˆ†å“åº”(Good) å’Œ 0åˆ†å“åº”(Bad) é…å¯¹
    
    Returns:
        dict: {dimension: {'pairs': [(good_item, bad_item), ...]}}
    """
    dimensions = ['helpfulness', 'correctness', 'coherence', 'complexity', 'verbosity']
    results = {dim: {'pairs': []} for dim in dimensions}
    
    for dimension in dimensions:
        print(f"\n  å¤„ç† {dimension}...")
        
        # æŒ‰ prompt åˆ†ç»„
        prompt_groups = defaultdict(lambda: {'score_0': [], 'score_4': []})
        
        for item in dataset:
            score = item.get(dimension)
            if score is None:
                continue
            
            prompt = item['prompt']
            
            if score == 0.0 or score == 0:
                prompt_groups[prompt]['score_0'].append(item)
            elif score == 4.0 or score == 4:
                prompt_groups[prompt]['score_4'].append(item)
        
        # ç»Ÿè®¡
        total_prompts = len(prompt_groups)
        prompts_with_0 = sum(1 for g in prompt_groups.values() if g['score_0'])
        prompts_with_4 = sum(1 for g in prompt_groups.values() if g['score_4'])
        prompts_with_both = sum(1 for g in prompt_groups.values() if g['score_0'] and g['score_4'])
        
        print(f"    æ€» prompts: {total_prompts}")
        print(f"    æœ‰0åˆ†çš„: {prompts_with_0}")
        print(f"    æœ‰4åˆ†çš„: {prompts_with_4}")
        print(f"    åŒæ—¶æœ‰0å’Œ4åˆ†çš„: {prompts_with_both}")
        
        # åˆ›å»ºé…å¯¹
        pair_count = 0
        for prompt, group in prompt_groups.items():
            score_0_items = group['score_0']
            score_4_items = group['score_4']
            
            if not score_0_items or not score_4_items:
                continue
            
            # ä¸ºæ¯ä¸ª 0åˆ†å“åº” å’Œ 4åˆ†å“åº” åˆ›å»ºé…å¯¹
            for bad_item in score_0_items:
                for good_item in score_4_items:
                    results[dimension]['pairs'].append({
                        'prompt': prompt,
                        'good_response': good_item['response'],
                        'bad_response': bad_item['response'],
                        'source': dataset_name,
                        'dimension': dimension
                    })
                    pair_count += 1
        
        print(f"    âœ… åˆ›å»ºé…å¯¹: {pair_count} å¯¹")
    
    return results


def merge_helpsteer_paired(output_dir="data/helpsteer_merged_paired"):
    """
    æ•´åˆ HelpSteer å’Œ HelpSteer2 æ•°æ®é›† (é…å¯¹ç­–ç•¥)
    """
    print("=" * 70)
    print("ğŸ“¥ åŠ è½½ HelpSteer å’Œ HelpSteer2 æ•°æ®é›†")
    print("=" * 70)
    
    # åŠ è½½æ•°æ®é›†
    print("\næ­£åœ¨åŠ è½½ HelpSteer...")
    helpsteer1 = load_dataset("nvidia/HelpSteer", split="train")
    print(f"âœ… HelpSteer: {len(helpsteer1)} æ¡")
    
    print("æ­£åœ¨åŠ è½½ HelpSteer2...")
    helpsteer2 = load_dataset("nvidia/HelpSteer2", split="train")
    print(f"âœ… HelpSteer2: {len(helpsteer2)} æ¡")
    
    print(f"\næ€»æ•°æ®é‡: {len(helpsteer1) + len(helpsteer2)} æ¡")
    
    # æ„å»ºé…å¯¹æ•°æ®
    print("\n" + "=" * 70)
    print("ï¿½ï¿½ï¸  æ„å»ºé…å¯¹æ•°æ® (åŒä¸€ prompt çš„ 0åˆ† vs 4åˆ†)")
    print("=" * 70)
    
    print("\n--- HelpSteer ---")
    pairs_hs1 = build_paired_extreme_data(helpsteer1, "helpsteer")
    
    print("\n--- HelpSteer2 ---")
    pairs_hs2 = build_paired_extreme_data(helpsteer2, "helpsteer2")
    
    # åˆå¹¶æ•°æ®
    print("\n" + "=" * 70)
    print("ğŸ”— åˆå¹¶é…å¯¹æ•°æ®")
    print("=" * 70)
    
    dimensions = ['helpfulness', 'correctness', 'coherence', 'complexity', 'verbosity']
    merged_pairs = {}
    
    for dim in dimensions:
        merged_pairs[dim] = pairs_hs1[dim]['pairs'] + pairs_hs2[dim]['pairs']
        
        print(f"\n  {dim.upper()}:")
        print(f"    HelpSteer:  {len(pairs_hs1[dim]['pairs']):5d} é…å¯¹")
        print(f"    HelpSteer2: {len(pairs_hs2[dim]['pairs']):5d} é…å¯¹")
        print(f"    åˆå¹¶å:     {len(merged_pairs[dim]):5d} é…å¯¹")
    
    # è½¬æ¢ä¸º good/bad pairs æ ¼å¼
    print("\n" + "=" * 70)
    print("ğŸ“¦ è½¬æ¢ä¸ºè®­ç»ƒæ ¼å¼")
    print("=" * 70)
    
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    for dim in dimensions:
        good_pairs = []
        bad_pairs = []
        
        for pair in merged_pairs[dim]:
            # Good pair
            good_pairs.append({
                'prompt': pair['prompt'],
                'response': pair['good_response'],
                'source': pair['source'],
                'original_score': 4,
                'label': 0
            })
            
            # Bad pair
            bad_pairs.append({
                'prompt': pair['prompt'],
                'response': pair['bad_response'],
                'source': pair['source'],
                'original_score': 0,
                'label': 1
            })
        
        # ä¿å­˜
        good_file = output_path / f"{dim}_good_pairs.json"
        bad_file = output_path / f"{dim}_bad_pairs.json"
        
        with open(good_file, 'w', encoding='utf-8') as f:
            json.dump(good_pairs, f, indent=2, ensure_ascii=False)
        
        with open(bad_file, 'w', encoding='utf-8') as f:
            json.dump(bad_pairs, f, indent=2, ensure_ascii=False)
        
        # éªŒè¯é…å¯¹
        assert len(good_pairs) == len(bad_pairs), f"{dim}: Good/Bad æ•°é‡ä¸åŒ¹é…!"
        
        # éªŒè¯ prompt åŒ¹é…
        good_prompts = [p['prompt'] for p in good_pairs]
        bad_prompts = [p['prompt'] for p in bad_pairs]
        assert good_prompts == bad_prompts, f"{dim}: Prompt é¡ºåºä¸åŒ¹é…!"
        
        print(f"  âœ… {dim}: {len(good_pairs)} é…å¯¹ (100% åŒ¹é…)")
    
    # ç»Ÿè®¡æ‘˜è¦
    print("\n" + "=" * 70)
    print("ğŸ“ˆ æœ€ç»ˆç»Ÿè®¡æ‘˜è¦")
    print("=" * 70)
    
    print("\né…å¯¹æ•°æ®é‡:")
    print("-" * 70)
    print(f"{'ç»´åº¦':<15} {'é…å¯¹æ•°':<10} {'è¯´æ˜':<30}")
    print("-" * 70)
    
    for dim in dimensions:
        pair_count = len(merged_pairs[dim])
        desc = "åŒä¸€promptçš„0åˆ†vs4åˆ†å“åº”"
        print(f"{dim:<15} {pair_count:<10,} {desc}")
    
    print("\n" + "=" * 70)
    print("âœ… HelpSteer é…å¯¹æ•°æ®æ•´åˆå®Œæˆ!")
    print("=" * 70)
    print(f"\nè¾“å‡ºç›®å½•: {output_dir}/")
    print("\nç‰¹ç‚¹:")
    print("  âœ… æ¯ä¸ª Good æ ·æœ¬éƒ½æœ‰å¯¹åº”çš„ Bad æ ·æœ¬")
    print("  âœ… éƒ½æ˜¯å¯¹åŒä¸€ä¸ª prompt çš„ä¸åŒè´¨é‡å“åº”")
    print("  âœ… æœ€å¤§åŒ–å·®å¼‚ (0åˆ† vs 4åˆ†)")
    print("\nä½¿ç”¨æ–¹æ³•:")
    print("  bash train_extreme_single.sh helpfulness --merged")


if __name__ == "__main__":
    merge_helpsteer_paired()
