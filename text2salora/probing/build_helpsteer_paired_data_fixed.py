"""
ä¿®æ­£ç‰ˆ: åŸºäºHelpSteeræ•°æ®é›†æ„å»ºå¤šç»´åº¦æ¢é’ˆè®­ç»ƒæ•°æ®
å…³é”®ä¿®æ”¹: å°†è¯„åˆ†è½¬æ¢ä¸º0/1æ ‡ç­¾
- é«˜åˆ†å›å¤ -> æ ‡ç­¾1 (å¥½)
- ä½åˆ†å›å¤ -> æ ‡ç­¾0 (å)
"""

from datasets import load_dataset
from collections import defaultdict
import json
import os
from tqdm import tqdm
import random


def build_paired_data_for_dimension(dataset, dimension, min_pairs=5000, score_threshold=2):
    """
    ä¸ºæŒ‡å®šç»´åº¦æ„å»ºé…å¯¹æ•°æ®
    
    å…³é”®å˜åŒ–: ä¸å†ä¿å­˜åŸå§‹è¯„åˆ†,è€Œæ˜¯è½¬æ¢ä¸º0/1æ ‡ç­¾
    - good_pairs (é«˜åˆ†) -> æ ‡ç­¾1
    - bad_pairs (ä½åˆ†) -> æ ‡ç­¾0
    
    Args:
        dataset: HelpSteeræ•°æ®é›†
        dimension: è¯„åˆ†ç»´åº¦åç§° (helpfulness, correctness, etc.)
        min_pairs: æœ€å°‘éœ€è¦çš„æ•°æ®å¯¹æ•°é‡
        score_threshold: åˆ†æ•°å·®é˜ˆå€¼,åªæœ‰å·®è·>=thresholdçš„æ‰ç®—æœ‰æ•ˆå¯¹æ¯”
    
    Returns:
        good_pairs: [(prompt, response, label=1), ...] é«˜åˆ†å›å¤
        bad_pairs: [(prompt, response, label=0), ...] ä½åˆ†å›å¤
    """
    print(f"\n{'='*70}")
    print(f"ğŸ“Š æ„å»ºç»´åº¦: {dimension}")
    print(f"{'='*70}")
    
    # æŒ‰promptåˆ†ç»„
    prompt_groups = defaultdict(list)
    
    print("ğŸ“¥ æŒ‰promptåˆ†ç»„æ•°æ®...")
    for item in tqdm(dataset):
        if item[dimension] is not None:
            prompt_groups[item['prompt']].append({
                'response': item['response'],
                'score': item[dimension]
            })
    
    print(f"âœ… å…±æœ‰ {len(prompt_groups)} ä¸ªä¸åŒçš„prompt")
    
    # å¯¹äºæ¯ä¸ªprompt,æ‰¾å‡ºè¯„åˆ†å·®å¼‚æœ€å¤§çš„å›å¤å¯¹
    good_pairs = []  # é«˜åˆ† -> æ ‡ç­¾1
    bad_pairs = []   # ä½åˆ† -> æ ‡ç­¾0
    
    print(f"ğŸ” æå–è¯„åˆ†å¯¹æ¯”æ˜æ˜¾çš„å›å¤å¯¹...")
    for prompt, responses in tqdm(prompt_groups.items()):
        if len(responses) < 2:
            continue
        
        # æŒ‰åˆ†æ•°æ’åº
        responses.sort(key=lambda x: x['score'])
        
        # å–æœ€ä½åˆ†å’Œæœ€é«˜åˆ†
        lowest = responses[0]
        highest = responses[-1]
        
        # åªæœ‰åˆ†æ•°å·®è·è¶³å¤Ÿå¤§æ‰åŠ å…¥
        if highest['score'] - lowest['score'] >= score_threshold:
            # âœ… å…³é”®ä¿®æ”¹: ä¿å­˜ä¸º0/1æ ‡ç­¾,è€Œä¸æ˜¯åŸå§‹è¯„åˆ†
            good_pairs.append({
                'prompt': prompt,
                'response': highest['response'],
                'label': 1,  # é«˜åˆ† = å¥½çš„å›å¤
                'original_score': float(highest['score'])  # ä»…ä¾›å‚è€ƒ
            })
            bad_pairs.append({
                'prompt': prompt,
                'response': lowest['response'],
                'label': 0,  # ä½åˆ† = åçš„å›å¤
                'original_score': float(lowest['score'])  # ä»…ä¾›å‚è€ƒ
            })
    
    print(f"\nğŸ“ˆ åˆæ­¥ç»Ÿè®¡:")
    print(f"   åŸå§‹é…å¯¹æ•°: {len(good_pairs)}")
    
    # å¦‚æœæ•°æ®ä¸å¤Ÿ,é™ä½é˜ˆå€¼é‡æ–°æå–
    if len(good_pairs) < min_pairs:
        print(f"âš ï¸  æ•°æ®é‡ä¸è¶³ {min_pairs},é™ä½é˜ˆå€¼åˆ°1é‡æ–°æå–...")
        good_pairs = []
        bad_pairs = []
        
        for prompt, responses in prompt_groups.items():
            if len(responses) < 2:
                continue
            
            responses.sort(key=lambda x: x['score'])
            lowest = responses[0]
            highest = responses[-1]
            
            if highest['score'] - lowest['score'] >= 1:
                good_pairs.append({
                    'prompt': prompt,
                    'response': highest['response'],
                    'label': 1,
                    'original_score': float(highest['score'])
                })
                bad_pairs.append({
                    'prompt': prompt,
                    'response': lowest['response'],
                    'label': 0,
                    'original_score': float(lowest['score'])
                })
    
    # å¦‚æœè¿˜æ˜¯ä¸å¤Ÿ,ç›´æ¥æŒ‰åˆ†æ•°ä¸­ä½æ•°åˆ†å‰²
    if len(good_pairs) < min_pairs:
        print(f"âš ï¸  æ•°æ®é‡ä»ä¸è¶³,ä½¿ç”¨ä¸­ä½æ•°åˆ†å‰²ç­–ç•¥...")
        all_responses = []
        for prompt, responses in prompt_groups.items():
            for r in responses:
                all_responses.append({
                    'prompt': prompt,
                    'response': r['response'],
                    'score': r['score']
                })
        
        # è®¡ç®—ä¸­ä½æ•°
        scores = [r['score'] for r in all_responses]
        median_score = sorted(scores)[len(scores)//2]
        
        # é«˜äºä¸­ä½æ•°=å¥½,ä½äºä¸­ä½æ•°=å
        good_pairs = []
        bad_pairs = []
        for r in all_responses:
            if r['score'] > median_score:
                good_pairs.append({
                    'prompt': r['prompt'],
                    'response': r['response'],
                    'label': 1,
                    'original_score': float(r['score'])
                })
            elif r['score'] < median_score:
                bad_pairs.append({
                    'prompt': r['prompt'],
                    'response': r['response'],
                    'label': 0,
                    'original_score': float(r['score'])
                })
        
        # æ‰“ä¹±å¹¶æˆªå–
        random.shuffle(good_pairs)
        random.shuffle(bad_pairs)
        good_pairs = good_pairs[:min_pairs]
        bad_pairs = bad_pairs[:min_pairs]
    
    # ç¡®ä¿æ•°é‡ä¸€è‡´ä¸”æ»¡è¶³æœ€å°è¦æ±‚
    min_available = min(len(good_pairs), len(bad_pairs))
    if min_available < min_pairs:
        print(f"âš ï¸  è­¦å‘Š: åªèƒ½æå– {min_available} å¯¹æ•°æ®")
    else:
        min_available = min_pairs
    
    good_pairs = good_pairs[:min_available]
    bad_pairs = bad_pairs[:min_available]
    
    # ç»Ÿè®¡ä¿¡æ¯
    good_scores = [p['original_score'] for p in good_pairs]
    bad_scores = [p['original_score'] for p in bad_pairs]
    
    print(f"\nâœ… æœ€ç»ˆæ•°æ®ç»Ÿè®¡:")
    print(f"   é…å¯¹æ•°é‡: {len(good_pairs)} å¯¹")
    print(f"   Goodæ•°æ® (label=1): {len(good_pairs)} æ¡")
    print(f"   Badæ•°æ® (label=0): {len(bad_pairs)} æ¡")
    print(f"   GoodåŸå§‹è¯„åˆ†: {min(good_scores):.1f}-{max(good_scores):.1f} (avg={sum(good_scores)/len(good_scores):.2f})")
    print(f"   BadåŸå§‹è¯„åˆ†: {min(bad_scores):.1f}-{max(bad_scores):.1f} (avg={sum(bad_scores)/len(bad_scores):.2f})")
    print(f"   å¹³å‡åˆ†å·®: {sum(good_scores)/len(good_scores) - sum(bad_scores)/len(bad_scores):.2f}")
    print(f"   âœ… æ‰€æœ‰æ•°æ®å·²æ ‡è®°ä¸º0/1æ ‡ç­¾ (è€ŒéåŸå§‹è¯„åˆ†)")
    
    return good_pairs, bad_pairs


def main():
    """ä¸»å‡½æ•°"""
    print("="*70)
    print("ğŸ”§ ä¿®æ­£ç‰ˆ: HelpSteerå¤šç»´åº¦é…å¯¹æ•°æ®æ„å»º")
    print("="*70)
    print("å…³é”®ä¿®æ”¹: è¯„åˆ†è½¬æ¢ä¸º0/1æ ‡ç­¾")
    print("  - é«˜åˆ†å›å¤ -> label=1 (å¥½)")
    print("  - ä½åˆ†å›å¤ -> label=0 (å)")
    print("="*70)
    
    # åŠ è½½æ•°æ®é›†
    print("\nğŸ“¥ åŠ è½½HelpSteeræ•°æ®é›†...")
    dataset = load_dataset("nvidia/HelpSteer", split="train")
    print(f"âœ… åŠ è½½å®Œæˆ! æ€»æ ·æœ¬æ•°: {len(dataset)}")
    
    # å®šä¹‰ç»´åº¦
    dimensions = {
        'helpfulness': 'æœ‰ç”¨æ€§',
        'correctness': 'æ­£ç¡®æ€§',
        'coherence': 'è¿è´¯æ€§',
        'complexity': 'å¤æ‚æ€§',
        'verbosity': 'å†—é•¿åº¦'
    }
    
    # è¾“å‡ºç›®å½•
    output_dir = 'data/helpsteer_paired'
    os.makedirs(output_dir, exist_ok=True)
    
    # ä¸ºæ¯ä¸ªç»´åº¦æ„å»ºæ•°æ®
    for dim_key, dim_name in dimensions.items():
        good_pairs, bad_pairs = build_paired_data_for_dimension(
            dataset, 
            dim_key, 
            min_pairs=5000,
            score_threshold=2
        )
        
        # ä¿å­˜æ•°æ®
        good_file = os.path.join(output_dir, f'{dim_key}_good_pairs.json')
        bad_file = os.path.join(output_dir, f'{dim_key}_bad_pairs.json')
        
        with open(good_file, 'w', encoding='utf-8') as f:
            json.dump(good_pairs, f, ensure_ascii=False, indent=2)
        
        with open(bad_file, 'w', encoding='utf-8') as f:
            json.dump(bad_pairs, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ å·²ä¿å­˜åˆ°:")
        print(f"   {good_file}")
        print(f"   {bad_file}")
    
    print("\n" + "="*70)
    print("âœ… æ‰€æœ‰ç»´åº¦æ•°æ®æ„å»ºå®Œæˆ!")
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"ğŸ“Š æ€»ç»´åº¦æ•°: {len(dimensions)}")
    print(f"ğŸ“Š æ€»æ•°æ®é‡: {len(dimensions) * 5000 * 2} æ¡ (5ä¸ªç»´åº¦ Ã— 5000å¯¹ Ã— 2)")
    print("="*70)
    
    # éªŒè¯æ ‡ç­¾
    print("\nğŸ” éªŒè¯æ ‡ç­¾æ ¼å¼...")
    for dim_key in dimensions.keys():
        good_file = os.path.join(output_dir, f'{dim_key}_good_pairs.json')
        with open(good_file, 'r') as f:
            sample = json.load(f)[0]
        print(f"   {dim_key}: label={sample['label']}, original_score={sample['original_score']}")
    print("âœ… æ‰€æœ‰æ ‡ç­¾æ ¼å¼æ­£ç¡®!")


if __name__ == '__main__':
    main()
