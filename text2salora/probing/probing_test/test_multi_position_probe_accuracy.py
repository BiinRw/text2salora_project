"""
å¤šä½ç½®æ¢é’ˆå‡†ç¡®åº¦æµ‹è¯•è„šæœ¬

åŠŸèƒ½:
1. åŠ è½½ä¸åŒç±»å‹çš„æ¨¡å‹(åŸºæ¨¡å‹/å¾®è°ƒæ¨¡å‹/LoRAæ¨¡å‹)
2. åŠ è½½å·²è®­ç»ƒçš„å¤šä½ç½®æ¢é’ˆ
3. åœ¨æµ‹è¯•æ•°æ®ä¸Šè¯„ä¼°æ¯ä¸ªä½ç½®ã€æ¯å±‚æ¢é’ˆçš„å‡†ç¡®åº¦
4. ç”Ÿæˆè¯¦ç»†çš„å¤šä½ç½®å¯¹æ¯”æµ‹è¯•æŠ¥å‘Š

ä½ç½®è¯´æ˜:
- user_last: ç”¨æˆ·é—®é¢˜çš„æœ€åä¸€ä¸ªtoken
- assistant_first: åŠ©æ‰‹å›ç­”çš„ç¬¬ä¸€ä¸ªtoken  
- assistant_last: åŠ©æ‰‹å›ç­”çš„æœ€åä¸€ä¸ªtoken (æ ‡å‡†)
- assistant_mean: åŠ©æ‰‹å›ç­”çš„æ‰€æœ‰tokenå¹³å‡

ä½¿ç”¨æ–¹æ³•:
python test_multi_position_probe_accuracy.py \
    --model_path Qwen/Qwen2.5-1.5B-Instruct \
    --lora_path /path/to/lora/checkpoint \
    --probe_dir ../results_multi_position/safety \
    --test_data ../data/safety_paired \
    --dimension safety \
    --positions assistant_last assistant_first \
    --max_samples 100 \
    --output_dir results/multi_position_test
"""

import torch
import numpy as np
from sklearn.metrics import accuracy_score, precision_recall_fscore_support
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel
from tqdm import tqdm
import json
import argparse
import os
import pickle
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple


class MultiPositionActivationExtractor:
    """æå–å¤šä¸ª token ä½ç½®çš„æ¿€æ´»å€¼ (å¤ç”¨è®­ç»ƒæ—¶çš„é€»è¾‘)"""
    
    def __init__(self, model, tokenizer, device='cuda:0'):
        self.model = model
        self.tokenizer = tokenizer
        self.device = device
        self.activations = {}
        self.hooks = []
        
        # è·å–æ¨¡å‹é…ç½®
        config = model.config
        self.num_layers = config.num_hidden_layers
        self.hidden_size = config.hidden_size
        self.num_heads = config.num_attention_heads
        self.head_dim = self.hidden_size // self.num_heads
        
        print(f"\nğŸ“Š æ¨¡å‹é…ç½®:")
        print(f"   å±‚æ•°: {self.num_layers}")
        print(f"   éšè—å±‚ç»´åº¦: {self.hidden_size}")
        print(f"   æ³¨æ„åŠ›å¤´æ•°: {self.num_heads}")
        print(f"   æ¯ä¸ªå¤´ç»´åº¦: {self.head_dim}")
    
    def _get_activation_hook(self, layer_id):
        """åˆ›å»º hook å‡½æ•°æ¥æ•è·å®Œæ•´åºåˆ—çš„æ¿€æ´»å€¼"""
        def hook(module, input, output):
            key = f"layer-{layer_id}"
            if key not in self.activations:
                self.activations[key] = []
            # ä¿å­˜å®Œæ•´åºåˆ—: (batch_size, seq_len, hidden_dim)
            self.activations[key].append(output.detach().cpu())
        return hook
    
    def register_hooks(self):
        """æ³¨å†Œ hooks åˆ°æ‰€æœ‰å±‚çš„ Q æŠ•å½±"""
        self.activations = {}
        self.hooks = []
        
        # å…¼å®¹ PeftModel å’ŒåŸºç¡€æ¨¡å‹
        if hasattr(self.model, 'get_base_model'):
            # PeftModel: ä½¿ç”¨ get_base_model() æ–¹æ³•
            base_model = self.model.get_base_model()
            base_layers = base_model.model.layers
        else:
            # åŸºç¡€æ¨¡å‹: model.model.layers
            base_layers = self.model.model.layers
        
        for layer_id in range(self.num_layers):
            layer = base_layers[layer_id]
            hook = layer.self_attn.q_proj.register_forward_hook(
                self._get_activation_hook(layer_id)
            )
            self.hooks.append(hook)
    
    def remove_hooks(self):
        """ç§»é™¤æ‰€æœ‰ hooks"""
        for hook in self.hooks:
            hook.remove()
        self.hooks = []
    
    def find_token_positions(self, text: str, inputs) -> Dict[str, int]:
        """
        å®šä½å…³é”® token ä½ç½®
        
        è¿”å›æ ¼å¼: {
            'user_last': int,
            'assistant_first': int,
            'assistant_last': int,
            'assistant_range': (start, end)
        }
        """
        tokens = self.tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])
        
        positions = {}
        
        # å¯»æ‰¾ assistant æ ‡è®°çš„ä½ç½®
        assistant_markers = ['assistant', '<|assistant|>', 'Assistant']
        assistant_start = -1
        
        for i, token in enumerate(tokens):
            for marker in assistant_markers:
                if marker.lower() in token.lower():
                    assistant_start = i
                    break
            if assistant_start != -1:
                break
        
        # å¦‚æœæ‰¾ä¸åˆ°åŠ©æ‰‹æ ‡è®°,ä½¿ç”¨ç®€å•çš„åˆ†å‰²ç­–ç•¥
        if assistant_start == -1:
            seq_len = len(tokens)
            assistant_start = seq_len // 2
        
        # è®¡ç®—å„ä¸ªä½ç½®
        positions['user_last'] = max(0, assistant_start - 1)
        positions['assistant_first'] = min(assistant_start + 1, len(tokens) - 1)
        positions['assistant_last'] = len(tokens) - 1
        positions['assistant_range'] = (assistant_start + 1, len(tokens))
        
        return positions
    
    def format_conversation(self, prompt, response):
        """æ ¼å¼åŒ–å¯¹è¯ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼"""
        messages = [
            {"role": "user", "content": prompt},
            {"role": "assistant", "content": response}
        ]
        text = self.tokenizer.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=False
        )
        return text
    
    def extract_from_pairs(self, pairs, max_samples=None, 
                          positions=['user_last', 'assistant_first', 'assistant_last', 'assistant_mean']):
        """
        ä»é…å¯¹æ•°æ®ä¸­æå–å¤šä¸ªä½ç½®çš„æ¿€æ´»å€¼
        
        Args:
            pairs: é…å¯¹æ•°æ®åˆ—è¡¨
            max_samples: æœ€å¤§æ ·æœ¬æ•°
            positions: è¦æå–çš„ä½ç½®åˆ—è¡¨
        
        Returns:
            Dict[position_name, Dict[head_key, activations]]
        """
        self.activations = {}
        self.register_hooks()
        
        print(f"ğŸ“¥ æå– {len(pairs)} ä¸ªé…å¯¹çš„æ¿€æ´»å€¼...")
        print(f"ğŸ“ æå–ä½ç½®: {', '.join(positions)}")
        self.model.eval()
        
        if max_samples:
            pairs = pairs[:max_samples]
        
        # å­˜å‚¨æ¯ä¸ªæ ·æœ¬çš„ä½ç½®ä¿¡æ¯
        position_indices = []
        
        with torch.no_grad():
            for pair in tqdm(pairs, desc="æå–æ¿€æ´»"):
                text = self.format_conversation(pair['prompt'], pair['response'])
                inputs = self.tokenizer(
                    text,
                    return_tensors='pt',
                    truncation=True,
                    max_length=512
                ).to(self.device)
                
                # è®°å½•ä½ç½®
                pos_info = self.find_token_positions(text, inputs)
                position_indices.append(pos_info)
                
                self.model(**inputs)
        
        self.remove_hooks()
        
        # æ•´ç†æ¿€æ´»å€¼: æŒ‰ä½ç½®å’Œæ³¨æ„åŠ›å¤´ç»„ç»‡
        print("ğŸ”„ æ•´ç†æ¿€æ´»å€¼...")
        result = {pos: {} for pos in positions}
        
        for layer_id in tqdm(range(self.num_layers), desc="å¤„ç†å±‚"):
            key = f"layer-{layer_id}"
            if key not in self.activations:
                continue
            
            layer_acts_list = self.activations[key]
            
            for head_id in range(self.num_heads):
                start_idx = head_id * self.head_dim
                end_idx = (head_id + 1) * self.head_dim
                head_key = f"layer-{layer_id}-head-{head_id}"
                
                # ä¸ºæ¯ä¸ªä½ç½®æå–æ¿€æ´»
                for pos_name in positions:
                    acts_for_position = []
                    
                    for sample_idx, (act_tensor, pos_info) in enumerate(zip(layer_acts_list, position_indices)):
                        # act_tensor: (1, seq_len, hidden_dim)
                        act = act_tensor[0, :, start_idx:end_idx].numpy()  # (seq_len, head_dim)
                        
                        if pos_name == 'user_last':
                            token_idx = pos_info['user_last']
                            acts_for_position.append(act[token_idx])
                        
                        elif pos_name == 'assistant_first':
                            token_idx = pos_info['assistant_first']
                            acts_for_position.append(act[token_idx])
                        
                        elif pos_name == 'assistant_last':
                            token_idx = pos_info['assistant_last']
                            acts_for_position.append(act[token_idx])
                        
                        elif pos_name == 'assistant_mean':
                            start, end = pos_info['assistant_range']
                            mean_act = act[start:end].mean(axis=0)
                            acts_for_position.append(mean_act)
                    
                    result[pos_name][head_key] = np.array(acts_for_position)
        
        print(f"âœ… æå–å®Œæˆ! æ¯ä¸ªä½ç½®å…± {len(result[positions[0]])} ä¸ªæ³¨æ„åŠ›å¤´")
        return result


def load_model(model_path, lora_path=None, device='cuda:0'):
    """åŠ è½½æ¨¡å‹"""
    print(f"\nğŸ”§ åŠ è½½æ¨¡å‹...")
    print(f"   åŸºæ¨¡å‹è·¯å¾„: {model_path}")
    if lora_path:
        print(f"   LoRAè·¯å¾„: {lora_path}")
    
    tokenizer = AutoTokenizer.from_pretrained(
        model_path,
        trust_remote_code=True
    )
    
    model = AutoModelForCausalLM.from_pretrained(
        model_path,
        torch_dtype=torch.float16,
        device_map=device,
        trust_remote_code=True
    )
    
    if lora_path:
        model = PeftModel.from_pretrained(model, lora_path)
        model_type = "lora"
        print(f"   âœ… LoRAé€‚é…å™¨å·²åŠ è½½")
    elif "checkpoint" in model_path or "finetuned" in model_path.lower():
        model_type = "finetuned"
    else:
        model_type = "base"
    
    print(f"   âœ… æ¨¡å‹ç±»å‹: {model_type}")
    print(f"   âœ… æ¨¡å‹å‚æ•°: {sum(p.numel() for p in model.parameters()) / 1e9:.2f}B")
    
    return model, tokenizer, model_type


def load_position_probes(probe_dir, position, dimension):
    """
    åŠ è½½æŒ‡å®šä½ç½®çš„æ¢é’ˆ
    
    Args:
        probe_dir: æ¢é’ˆæ ¹ç›®å½•
        position: ä½ç½®åç§° (å¦‚ assistant_last)
        dimension: ç»´åº¦åç§° (å¦‚ safety)
        
    Returns:
        dict: {head_key: LogisticRegressionæ¨¡å‹}
    """
    # æ„å»ºæ¢é’ˆæ–‡ä»¶è·¯å¾„: {dimension}_{position}_probes/
    probe_subdir = os.path.join(probe_dir, f"{dimension}_{position}_probes")
    
    if not os.path.exists(probe_subdir):
        raise FileNotFoundError(f"æ¢é’ˆç›®å½•ä¸å­˜åœ¨: {probe_subdir}")
    
    print(f"\nğŸ“‚ åŠ è½½æ¢é’ˆ [{position}]...")
    print(f"   æ¢é’ˆç›®å½•: {probe_subdir}")
    
    # åŠ è½½æ‰€æœ‰æ¢é’ˆæ–‡ä»¶
    probes = {}
    probe_files = sorted([f for f in os.listdir(probe_subdir) if f.endswith('.pkl')])
    
    for probe_file in probe_files:
        # æ–‡ä»¶åæ ¼å¼: layer-{layer_id}-head-{head_id}.pkl
        probe_path = os.path.join(probe_subdir, probe_file)
        with open(probe_path, 'rb') as f:
            probe = pickle.load(f)
        
        # æå– key: layer-{layer_id}-head-{head_id}
        key = probe_file.replace('.pkl', '')
        probes[key] = probe
    
    print(f"   âœ… å·²åŠ è½½ {len(probes)} ä¸ªæ¢é’ˆ")
    
    return probes


def load_test_data(test_data_dir, dimension):
    """åŠ è½½æµ‹è¯•æ•°æ®"""
    good_file = os.path.join(test_data_dir, f"{dimension}_good_pairs.json")
    bad_file = os.path.join(test_data_dir, f"{dimension}_bad_pairs.json")
    
    # å°è¯•å…¶ä»–å¯èƒ½çš„æ–‡ä»¶å
    if not os.path.exists(good_file):
        good_file = os.path.join(test_data_dir, "safe_pairs_large.json")
    if not os.path.exists(bad_file):
        bad_file = os.path.join(test_data_dir, "harmful_pairs_large.json")
    
    print(f"\nğŸ“‚ åŠ è½½æµ‹è¯•æ•°æ®...")
    print(f"   å¥½æ ·æœ¬: {good_file}")
    print(f"   åæ ·æœ¬: {bad_file}")
    
    with open(good_file, 'r', encoding='utf-8') as f:
        good_samples = json.load(f)
    
    with open(bad_file, 'r', encoding='utf-8') as f:
        bad_samples = json.load(f)
    
    print(f"   âœ… å¥½æ ·æœ¬æ•°: {len(good_samples)}")
    print(f"   âœ… åæ ·æœ¬æ•°: {len(bad_samples)}")
    
    return good_samples, bad_samples


def evaluate_position_probes(probes, good_activations, bad_activations):
    """
    è¯„ä¼°æŒ‡å®šä½ç½®çš„æ¢é’ˆæ€§èƒ½
    
    Args:
        probes: {head_key: probe_model}
        good_activations: {head_key: np.array}
        bad_activations: {head_key: np.array}
    
    Returns:
        results: {head_key: metrics_dict}
    """
    results = {}
    
    for head_key in tqdm(probes.keys(), desc="è¯„ä¼°æ¢é’ˆ"):
        if head_key not in good_activations or head_key not in bad_activations:
            continue
        
        probe = probes[head_key]
        
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        X_good = good_activations[head_key]
        X_bad = bad_activations[head_key]
        
        X_test = np.vstack([X_good, X_bad])
        y_test = np.array([1] * len(X_good) + [0] * len(X_bad))
        
        # é¢„æµ‹
        y_pred = probe.predict(X_test)
        
        # è®¡ç®—æŒ‡æ ‡
        accuracy = accuracy_score(y_test, y_pred)
        precision, recall, f1, _ = precision_recall_fscore_support(
            y_test, y_pred, average='binary', zero_division=0
        )
        
        results[head_key] = {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1': f1,
            'n_samples': len(y_test)
        }
    
    return results


def print_position_summary(position, results):
    """æ‰“å°å•ä¸ªä½ç½®çš„ç»Ÿè®¡æ‘˜è¦"""
    accuracies = [r['accuracy'] for r in results.values()]
    f1_scores = [r['f1'] for r in results.values()]
    
    print(f"\n{'='*80}")
    print(f"ğŸ“ ä½ç½®: {position}")
    print(f"{'='*80}")
    print(f"æ¢é’ˆæ•°é‡: {len(results)}")
    print(f"å¹³å‡å‡†ç¡®ç‡: {np.mean(accuracies):.4f} Â± {np.std(accuracies):.4f}")
    print(f"å¹³å‡ F1: {np.mean(f1_scores):.4f} Â± {np.std(f1_scores):.4f}")
    print(f"æœ€é«˜å‡†ç¡®ç‡: {np.max(accuracies):.4f}")
    print(f"æœ€ä½å‡†ç¡®ç‡: {np.min(accuracies):.4f}")
    print(f"å‡†ç¡®ç‡ >= 0.8: {sum(1 for a in accuracies if a >= 0.8)}")
    print(f"å‡†ç¡®ç‡ >= 0.9: {sum(1 for a in accuracies if a >= 0.9)}")


def save_results(output_dir, dimension, model_type, all_position_results):
    """ä¿å­˜æµ‹è¯•ç»“æœ"""
    os.makedirs(output_dir, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # ä¿å­˜è¯¦ç»†ç»“æœ (JSON)
    results_file = os.path.join(
        output_dir, 
        f"{dimension}_{model_type}_multi_position_test_{timestamp}.json"
    )
    
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(all_position_results, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜:")
    print(f"   {results_file}")
    
    # ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š
    report_file = os.path.join(
        output_dir,
        f"{dimension}_{model_type}_multi_position_report_{timestamp}.txt"
    )
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("="*80 + "\n")
        f.write(f"å¤šä½ç½®æ¢é’ˆæµ‹è¯•æŠ¥å‘Š\n")
        f.write("="*80 + "\n")
        f.write(f"ç»´åº¦: {dimension}\n")
        f.write(f"æ¨¡å‹ç±»å‹: {model_type}\n")
        f.write(f"æµ‹è¯•æ—¶é—´: {timestamp}\n")
        f.write("="*80 + "\n\n")
        
        # ä½ç½®å¯¹æ¯”æ±‡æ€»
        f.write("ğŸ“Š ä½ç½®æ€§èƒ½å¯¹æ¯”\n")
        f.write("-"*80 + "\n")
        
        position_summary = {}
        for pos_name, pos_results in all_position_results.items():
            accuracies = [r['accuracy'] for r in pos_results.values()]
            position_summary[pos_name] = {
                'mean_acc': np.mean(accuracies),
                'std_acc': np.std(accuracies),
                'max_acc': np.max(accuracies),
                'count_80': sum(1 for a in accuracies if a >= 0.8),
                'count_90': sum(1 for a in accuracies if a >= 0.9)
            }
        
        # æŒ‰å¹³å‡å‡†ç¡®ç‡æ’åº
        sorted_positions = sorted(
            position_summary.items(),
            key=lambda x: x[1]['mean_acc'],
            reverse=True
        )
        
        for pos_name, summary in sorted_positions:
            f.write(f"\nğŸ“ {pos_name}\n")
            f.write(f"   å¹³å‡å‡†ç¡®ç‡: {summary['mean_acc']:.4f} Â± {summary['std_acc']:.4f}\n")
            f.write(f"   æœ€é«˜å‡†ç¡®ç‡: {summary['max_acc']:.4f}\n")
            f.write(f"   å‡†ç¡®ç‡>=0.8: {summary['count_80']}\n")
            f.write(f"   å‡†ç¡®ç‡>=0.9: {summary['count_90']}\n")
        
        # è¯¦ç»†çš„æ¯å±‚ç»“æœ
        f.write("\n\n" + "="*80 + "\n")
        f.write("ğŸ“Š è¯¦ç»†çš„æ¯å±‚ç»“æœ\n")
        f.write("="*80 + "\n")
        
        for pos_name, pos_results in all_position_results.items():
            f.write(f"\n\n{'='*80}\n")
            f.write(f"ä½ç½®: {pos_name}\n")
            f.write(f"{'='*80}\n")
            
            # æŒ‰layeræ’åº
            sorted_heads = sorted(pos_results.keys())
            for head_key in sorted_heads:
                metrics = pos_results[head_key]
                f.write(f"\n{head_key}:\n")
                f.write(f"  å‡†ç¡®ç‡: {metrics['accuracy']:.4f}\n")
                f.write(f"  ç²¾ç¡®ç‡: {metrics['precision']:.4f}\n")
                f.write(f"  å¬å›ç‡: {metrics['recall']:.4f}\n")
                f.write(f"  F1åˆ†æ•°: {metrics['f1']:.4f}\n")
    
    print(f"   {report_file}")


def main():
    parser = argparse.ArgumentParser(description='å¤šä½ç½®æ¢é’ˆå‡†ç¡®åº¦æµ‹è¯•')
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--model_path', type=str, required=True, 
                       help='åŸºç¡€æ¨¡å‹è·¯å¾„')
    parser.add_argument('--lora_path', type=str, default=None,
                       help='LoRAé€‚é…å™¨è·¯å¾„ (å¯é€‰)')
    parser.add_argument('--device', type=str, default='cuda:0',
                       help='è®¡ç®—è®¾å¤‡')
    
    # æ¢é’ˆå‚æ•°
    parser.add_argument('--probe_dir', type=str, required=True,
                       help='æ¢é’ˆæ ¹ç›®å½• (åŒ…å«å¤šä¸ªä½ç½®çš„æ¢é’ˆ)')
    parser.add_argument('--positions', type=str, nargs='+',
                       default=['assistant_last'],
                       choices=['user_last', 'assistant_first', 'assistant_last', 'assistant_mean'],
                       help='è¦æµ‹è¯•çš„ä½ç½®åˆ—è¡¨')
    
    # æ•°æ®å‚æ•°
    parser.add_argument('--test_data', type=str, required=True,
                       help='æµ‹è¯•æ•°æ®ç›®å½•')
    parser.add_argument('--dimension', type=str, required=True,
                       help='æµ‹è¯•ç»´åº¦ (å¦‚ safety, helpfulness)')
    parser.add_argument('--max_samples', type=int, default=None,
                       help='æœ€å¤§æµ‹è¯•æ ·æœ¬æ•°')
    
    # è¾“å‡ºå‚æ•°
    parser.add_argument('--output_dir', type=str, default='results',
                       help='ç»“æœè¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    print("\n" + "="*80)
    print("ğŸ§ª å¤šä½ç½®æ¢é’ˆå‡†ç¡®åº¦æµ‹è¯•")
    print("="*80)
    print(f"ğŸ“Š ç»´åº¦: {args.dimension}")
    print(f"ğŸ“ æµ‹è¯•ä½ç½®: {', '.join(args.positions)}")
    print(f"ğŸ“ æ¢é’ˆç›®å½•: {args.probe_dir}")
    print(f"ğŸ“ æµ‹è¯•æ•°æ®: {args.test_data}")
    if args.max_samples:
        print(f"ğŸ“¦ æµ‹è¯•æ ·æœ¬æ•°: {args.max_samples}")
    print("="*80)
    
    # 1. åŠ è½½æ¨¡å‹
    model, tokenizer, model_type = load_model(
        args.model_path,
        args.lora_path,
        args.device
    )
    
    # 2. åŠ è½½æµ‹è¯•æ•°æ®
    good_samples, bad_samples = load_test_data(args.test_data, args.dimension)
    
    # 3. åˆ›å»ºæ¿€æ´»æå–å™¨
    extractor = MultiPositionActivationExtractor(model, tokenizer, args.device)
    
    # 4. æå–å¤šä½ç½®æ¿€æ´»
    print(f"\n{'='*80}")
    print("ğŸ” æå–æ¿€æ´»å€¼ (æ‰€æœ‰ä½ç½®)")
    print(f"{'='*80}")
    
    good_acts_multi = extractor.extract_from_pairs(
        good_samples,
        args.max_samples,
        args.positions
    )
    
    bad_acts_multi = extractor.extract_from_pairs(
        bad_samples,
        args.max_samples,
        args.positions
    )
    
    # 5. ä¸ºæ¯ä¸ªä½ç½®åŠ è½½æ¢é’ˆå¹¶æµ‹è¯•
    all_position_results = {}
    
    for position in args.positions:
        print(f"\n{'='*80}")
        print(f"ğŸ§ª æµ‹è¯•ä½ç½®: {position}")
        print(f"{'='*80}")
        
        # åŠ è½½è¯¥ä½ç½®çš„æ¢é’ˆ
        try:
            probes = load_position_probes(args.probe_dir, position, args.dimension)
        except FileNotFoundError as e:
            print(f"âš ï¸  è·³è¿‡ä½ç½® {position}: {e}")
            continue
        
        # è¯„ä¼°è¯¥ä½ç½®çš„æ¢é’ˆ
        position_results = evaluate_position_probes(
            probes,
            good_acts_multi[position],
            bad_acts_multi[position]
        )
        
        all_position_results[position] = position_results
        
        # æ‰“å°è¯¥ä½ç½®çš„ç»Ÿè®¡æ‘˜è¦
        print_position_summary(position, position_results)
    
    # 6. ä¿å­˜ç»“æœ
    if all_position_results:
        save_results(args.output_dir, args.dimension, model_type, all_position_results)
        
        print(f"\n{'='*80}")
        print("âœ… æµ‹è¯•å®Œæˆ!")
        print(f"{'='*80}")
    else:
        print(f"\nâš ï¸  æ²¡æœ‰æˆåŠŸæµ‹è¯•ä»»ä½•ä½ç½®")


if __name__ == '__main__':
    main()
