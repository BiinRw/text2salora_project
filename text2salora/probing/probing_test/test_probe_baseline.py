"""
Baselineæµ‹è¯•ï¼šä¸ä½¿ç”¨LoRAå’Œçº¦æŸï¼Œåªç”¨base modelæµ‹è¯•æ¢é’ˆ
ç”¨äºéªŒè¯æ¢é’ˆå’Œä½ç½®æå–é€»è¾‘æ˜¯å¦æ­£ç¡®
"""

import torch
import numpy as np
from sklearn.metrics import accuracy_score
from transformers import AutoTokenizer, AutoModelForCausalLM
from pathlib import Path
import pickle
import json
import argparse
from typing import List, Dict


class BaselineActivationExtractor:
    """Base modelæ¿€æ´»å€¼æå–å™¨"""
    
    def __init__(self, model, tokenizer, device='cuda'):
        self.model = model
        self.tokenizer = tokenizer
        self.device = device
        self.activations = {}
        self.hooks = []
        
        if hasattr(model, 'model'):
            self.transformer = model.model
        else:
            self.transformer = model
    
    def register_hooks(self):
        """æ³¨å†Œhookæå–q_projæ¿€æ´»å€¼"""
        def get_activation_hook(name):
            def hook(module, input, output):
                if isinstance(output, tuple):
                    output = output[0]
                self.activations[name] = output.detach().cpu()
            return hook
        
        for i, layer in enumerate(self.transformer.layers):
            hook = layer.self_attn.q_proj.register_forward_hook(get_activation_hook(f'layer_{i}'))
            self.hooks.append(hook)
    
    def remove_hooks(self):
        for hook in self.hooks:
            hook.remove()
        self.hooks = []
    
    def find_token_positions(self, inputs) -> Dict[str, int]:
        """å®šä½å…³é”®tokenä½ç½®"""
        token_ids = inputs['input_ids'][0]
        
        im_start_id = self.tokenizer.convert_tokens_to_ids('<|im_start|>')
        im_end_id = self.tokenizer.convert_tokens_to_ids('<|im_end|>')
        
        im_start_positions = (token_ids == im_start_id).nonzero(as_tuple=True)[0].tolist()
        im_end_positions = (token_ids == im_end_id).nonzero(as_tuple=True)[0].tolist()
        
        if len(im_start_positions) < 2 or len(im_end_positions) < 2:
            seq_len = len(token_ids)
            mid_point = seq_len // 2
            positions = {
                'user_last': max(0, mid_point - 1),
                'assistant_first': mid_point,
                'assistant_last': seq_len - 2,
                'assistant_range': (mid_point, seq_len - 1)
            }
            return positions
        
        user_end_pos = im_end_positions[0]
        assistant_start_marker = im_start_positions[1]
        assistant_end_pos = im_end_positions[1]
        
        positions = {
            'user_last': user_end_pos - 1,
            'assistant_first': assistant_start_marker + 2,
            'assistant_last': assistant_end_pos - 1,
            'assistant_range': (assistant_start_marker + 2, assistant_end_pos)
        }
        
        return positions
    
    def extract_activations(self, text: str, position: str) -> Dict:
        """æå–æŒ‡å®šä½ç½®çš„æ¿€æ´»å€¼ï¼ˆæŒ‰headåˆ†ç¦»ï¼‰"""
        inputs = self.tokenizer(text, return_tensors='pt', padding=True, 
                               truncation=True, max_length=512)
        inputs = {k: v.to(self.device) for k, v in inputs.items()}
        
        self.activations = {}
        self.register_hooks()
        
        with torch.no_grad():
            _ = self.model(**inputs)
        
        token_positions = self.find_token_positions(inputs)
        
        # è·å–æ¨¡å‹é…ç½®
        if hasattr(self.model, 'config'):
            num_heads = self.model.config.num_attention_heads
            head_dim = self.model.config.hidden_size // num_heads
        else:
            num_heads = 12
            head_dim = 128
        
        result = {}
        
        for layer_key, activation in self.activations.items():
            activation = activation[0].numpy()
            layer_id = int(layer_key.split('_')[1])
            
            if position == 'assistant_mean':
                start, end = token_positions['assistant_range']
                pos_activation = activation[start:end].mean(axis=0)
            else:
                token_idx = token_positions[position]
                pos_activation = activation[token_idx]
            
            # åˆ†ç¦»æˆå„ä¸ªå¤´
            for head_id in range(num_heads):
                start_idx = head_id * head_dim
                end_idx = start_idx + head_dim
                head_activation = pos_activation[start_idx:end_idx]
                head_key = f'layer_{layer_id}_head_{head_id}'
                result[head_key] = head_activation
        
        self.remove_hooks()
        return result


def load_probes(probe_dir: Path, dimension: str, position: str) -> Dict:
    """åŠ è½½æ¢é’ˆ"""
    probe_dir_path = probe_dir / dimension / f"{dimension}_{position}_probes"
    
    if not probe_dir_path.exists():
        raise FileNotFoundError(f"æ¢é’ˆç›®å½•ä¸å­˜åœ¨: {probe_dir_path}")
    
    probes = {}
    probe_files = list(probe_dir_path.glob("layer-*-head-*.pkl"))
    
    if not probe_files:
        raise FileNotFoundError(f"æ¢é’ˆç›®å½•ä¸ºç©º: {probe_dir_path}")
    
    for probe_file in probe_files:
        parts = probe_file.stem.split('-')
        layer_id = int(parts[1])
        head_id = int(parts[3])
        
        with open(probe_file, 'rb') as f:
            probe_data = pickle.load(f)
        
        if layer_id not in probes:
            probes[layer_id] = {}
        probes[layer_id][head_id] = probe_data
    
    print(f"âœ“ åŠ è½½æ¢é’ˆ: {len(probes)} å±‚, å…± {sum(len(h) for h in probes.values())} ä¸ªæ¢é’ˆ")
    return probes


def load_test_data(data_path: str, dimension: str, max_samples: int = None):
    """åŠ è½½æµ‹è¯•æ•°æ®"""
    data_path = Path(data_path)
    
    if dimension == 'safety':
        good_file = data_path / 'safe_pairs.json'
        bad_file = data_path / 'harmful_pairs.json'
    else:
        good_file = data_path / f'{dimension}_good_pairs.json'
        bad_file = data_path / f'{dimension}_bad_pairs.json'
    
    texts = []
    labels = []
    
    with open(good_file, 'r', encoding='utf-8') as f:
        good_data = json.load(f)
        if max_samples:
            good_data = good_data[:max_samples // 2]
        
        for item in good_data:
            text = f"<|im_start|>user\n{item['prompt']}<|im_end|>\n<|im_start|>assistant\n{item['response']}<|im_end|>"
            texts.append(text)
            labels.append(0)
    
    with open(bad_file, 'r', encoding='utf-8') as f:
        bad_data = json.load(f)
        if max_samples:
            bad_data = bad_data[:max_samples // 2]
        
        for item in bad_data:
            text = f"<|im_start|>user\n{item['prompt']}<|im_end|>\n<|im_start|>assistant\n{item['response']}<|im_end|>"
            texts.append(text)
            labels.append(1)
    
    return texts, labels


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--model_path', type=str, default='Qwen/Qwen2.5-1.5B-Instruct')
    parser.add_argument('--probe_dir', type=str, default='../trained_probes/multi_position-1103')
    parser.add_argument('--test_data', type=str, default='../data/safety_paired')
    parser.add_argument('--dimension', type=str, default='safety')
    parser.add_argument('--position', type=str, default='assistant_last')
    parser.add_argument('--max_samples', type=int, default=100)
    parser.add_argument('--device', type=str, default='cuda:3')
    
    args = parser.parse_args()
    
    print("\n" + "="*80)
    print("ğŸ§ª Baselineæµ‹è¯•ï¼šBase Model + æ¢é’ˆ")
    print("="*80)
    print(f"æ¨¡å‹: {args.model_path}")
    print(f"ç»´åº¦: {args.dimension}")
    print(f"ä½ç½®: {args.position}")
    print(f"è®¾å¤‡: {args.device}")
    print("="*80 + "\n")
    
    # åŠ è½½base model
    print("ğŸ“¥ åŠ è½½ Base Model...")
    tokenizer = AutoTokenizer.from_pretrained(args.model_path, trust_remote_code=True)
    model = AutoModelForCausalLM.from_pretrained(
        args.model_path,
        torch_dtype=torch.float16,
        device_map=args.device,
        trust_remote_code=True
    )
    model.eval()
    print("âœ“ Base Model åŠ è½½å®Œæˆ\n")
    
    # åŠ è½½æ¢é’ˆ
    print("ğŸ“‚ åŠ è½½æ¢é’ˆ...")
    probes = load_probes(Path(args.probe_dir), args.dimension, args.position)
    print()
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    print("ğŸ“Š åŠ è½½æµ‹è¯•æ•°æ®...")
    texts, labels = load_test_data(args.test_data, args.dimension, args.max_samples)
    print(f"âœ“ åŠ è½½ {len(texts)} æ¡æ•°æ® (Good: {labels.count(0)}, Bad: {labels.count(1)})\n")
    
    # æå–æ¿€æ´»å€¼
    print("ğŸ” æå–æ¿€æ´»å€¼...")
    extractor = BaselineActivationExtractor(model, tokenizer, args.device)
    activations_list = []
    
    for i, text in enumerate(texts):
        if (i + 1) % 50 == 0:
            print(f"  è¿›åº¦: {i+1}/{len(texts)}")
        
        act = extractor.extract_activations(text, args.position)
        activations_list.append(act)
    
    print(f"  è¿›åº¦: {len(texts)}/{len(texts)}")
    print()
    
    # æµ‹è¯•æ¢é’ˆå‡†ç¡®åº¦
    print("ğŸ“Š æµ‹è¯•æ¢é’ˆå‡†ç¡®åº¦...")
    results = {}
    y = np.array(labels)
    
    for layer_id, heads in probes.items():
        layer_accuracies = []
        
        for head_id, probe in heads.items():
            head_key = f'layer_{layer_id}_head_{head_id}'
            
            try:
                X = np.array([act[head_key] for act in activations_list])
                y_pred = probe.predict(X)
                acc = accuracy_score(y, y_pred)
                layer_accuracies.append(acc)
                results[head_key] = acc
            except KeyError:
                continue
            except Exception as e:
                print(f"âš  {head_key} é¢„æµ‹å¤±è´¥: {e}")
                continue
        
        if layer_accuracies:
            layer_key = f'layer_{layer_id}'
            results[layer_key] = np.mean(layer_accuracies)
    
    # è®¡ç®—å¹³å‡å‡†ç¡®ç‡ï¼ˆåªç®—layerçº§åˆ«ï¼‰
    layer_accs = [v for k, v in results.items() if k.startswith('layer_') and '_head_' not in k]
    avg_acc = np.mean(layer_accs) if layer_accs else 0.0
    
    # æ‰“å°ç»“æœ
    print("\n" + "="*80)
    print("ğŸ“Š æµ‹è¯•ç»“æœ")
    print("="*80)
    print(f"å¹³å‡å‡†ç¡®ç‡: {avg_acc:.4f}")
    print(f"\nå„å±‚å‡†ç¡®ç‡ (å‰10å±‚):")
    
    layer_results = [(k, v) for k, v in results.items() if k.startswith('layer_') and '_head_' not in k]
    layer_results.sort(key=lambda x: int(x[0].split('_')[1]))
    
    for layer_key, acc in layer_results[:10]:
        print(f"  {layer_key}: {acc:.4f}")
    
    if len(layer_results) > 10:
        print(f"  ...")
    
    # ä¿å­˜ç»“æœ
    output_file = f"baseline_result_{args.dimension}_{args.position}.json"
    output_data = {
        'model_path': args.model_path,
        'dimension': args.dimension,
        'position': args.position,
        'num_samples': len(texts),
        'layer_accuracies': results,
        'average_accuracy': avg_acc
    }
    
    with open(output_file, 'w') as f:
        json.dump(output_data, f, indent=2)
    
    print(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    print("="*80 + "\n")


if __name__ == '__main__':
    main()
