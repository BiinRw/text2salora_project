"""
LoRA â–³Wæ¶ˆèæµ‹è¯• - æ¢é’ˆå‡†ç¡®ç‡ç‰ˆæœ¬

åŠŸèƒ½ï¼šæµ‹è¯•ä¸åŒå±‚çš„LoRAâ–³Wç¦ç”¨å¯¹æ¢é’ˆå‡†ç¡®ç‡çš„å½±å“
ç”¨é€”ï¼šéªŒè¯è¡¨ç¤ºå¯åˆ†ç¦»æ€§ â‰  è¡Œä¸ºå®‰å…¨æ€§ç†è®º

ä½¿ç”¨æ–¹æ³•ï¼š
python test_ablation_probes.py \
    --lora_path <lora_checkpoint_path> \
    --probe_path <probe_model_path> \
    --output_dir ./results/ablation_probes
"""

import torch
import argparse
import json
import os
import sys
from pathlib import Path
from typing import List, Dict, Tuple
import logging
from datetime import datetime

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# å¯¼å…¥æ¶ˆèæµ‹è¯•å™¨
sys.path.insert(0, str(Path(__file__).parent))
from lora_ablation_tester import LoRAAblusionTester


class ProbeAccuracyEvaluator:
    """æ¢é’ˆå‡†ç¡®ç‡è¯„ä¼°å™¨"""
    
    def __init__(self, model, probe_model, device: str = 'cuda:0'):
        """
        åˆå§‹åŒ–æ¢é’ˆå‡†ç¡®ç‡è¯„ä¼°å™¨
        
        Args:
            model: ä¸»æ¨¡å‹
            probe_model: æ¢é’ˆåˆ†ç±»å™¨
            device: è®¾å¤‡
        """
        self.model = model
        self.probe_model = probe_model
        self.device = device
        self.probe_model.eval()
        self.probe_model.to(device)
    
    def get_model_hidden_states(self, test_prompts: List[str], layer_id: int = -1) -> torch.Tensor:
        """
        è·å–æ¨¡å‹éšå±‚è¡¨ç¤º
        
        Args:
            test_prompts: æµ‹è¯•æç¤ºåˆ—è¡¨
            layer_id: å±‚ID (-1è¡¨ç¤ºæœ€åä¸€å±‚)
            
        Returns:
            éšå±‚å¼ é‡ [batch_size, hidden_dim]
        """
        try:
            # è¿™é‡Œåº”è¯¥å®ç°ä»æ¨¡å‹è·å–éšå±‚è¾“å‡ºçš„é€»è¾‘
            # ç¤ºä¾‹ï¼šä½¿ç”¨hookæœºåˆ¶
            hidden_states = []
            
            def hook_fn(module, input, output):
                if isinstance(output, tuple):
                    hidden_states.append(output[0].detach().cpu())
                else:
                    hidden_states.append(output.detach().cpu())
            
            # æ³¨å†Œhook
            target_layer = list(self.model.modules())[layer_id]
            handle = target_layer.register_forward_hook(hook_fn)
            
            # å‰å‘ä¼ æ’­
            with torch.no_grad():
                _ = self.model(test_prompts)
            
            # ç§»é™¤hook
            handle.remove()
            
            if hidden_states:
                return torch.cat(hidden_states, dim=0)
            else:
                return torch.zeros(len(test_prompts), 1024)
        
        except Exception as e:
            logger.error(f"âŒ è·å–éšå±‚å¤±è´¥: {e}")
            return torch.zeros(len(test_prompts), 1024)
    
    def evaluate_probe_accuracy(self, test_prompts: List[str], test_labels: List[int]) -> float:
        """
        è¯„ä¼°æ¢é’ˆå‡†ç¡®ç‡
        
        Args:
            test_prompts: æµ‹è¯•æç¤ºåˆ—è¡¨
            test_labels: æµ‹è¯•æ ‡ç­¾åˆ—è¡¨
            
        Returns:
            å‡†ç¡®ç‡ (0.0-1.0)
        """
        try:
            # è·å–æœ€åä¸€å±‚éšå±‚è¡¨ç¤º
            hidden_states = self.get_model_hidden_states(test_prompts, layer_id=-1)
            
            # ç”¨æ¢é’ˆåˆ†ç±»å™¨è¯„ä¼°
            with torch.no_grad():
                hidden_states = hidden_states.to(self.device)
                logits = self.probe_model(hidden_states)
                predictions = torch.argmax(logits, dim=1).cpu().numpy()
            
            # è®¡ç®—å‡†ç¡®ç‡
            test_labels = torch.tensor(test_labels).numpy()
            accuracy = (predictions == test_labels).sum() / len(test_labels)
            
            return float(accuracy)
        
        except Exception as e:
            logger.error(f"âŒ æ¢é’ˆå‡†ç¡®ç‡è¯„ä¼°å¤±è´¥: {e}")
            return 0.0


def run_ablation_experiment(args):
    """è¿è¡Œæ¢é’ˆæ¶ˆèå®éªŒ"""
    
    logger.info("=" * 70)
    logger.info("ğŸ§ª LoRA â–³W æ¶ˆèæµ‹è¯• - æ¢é’ˆå‡†ç¡®ç‡ç‰ˆæœ¬")
    logger.info("=" * 70)
    
    # ç¬¬1æ­¥: åŠ è½½æ¨¡å‹
    logger.info("\n[1] åŠ è½½æ¨¡å‹...")
    try:
        from transformers import AutoModelForCausalLM, AutoTokenizer
        
        model = AutoModelForCausalLM.from_pretrained(
            args.model_path,
            torch_dtype=torch.float16,
            device_map=args.device
        )
        tokenizer = AutoTokenizer.from_pretrained(args.model_path)
        logger.info("   âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        logger.error(f"   âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return
    
    # ç¬¬2æ­¥: åŠ è½½æ¢é’ˆæ¨¡å‹
    logger.info("\n[2] åŠ è½½æ¢é’ˆæ¨¡å‹...")
    try:
        probe_model = torch.load(args.probe_path)
        logger.info("   âœ… æ¢é’ˆæ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        logger.error(f"   âŒ æ¢é’ˆæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return
    
    # ç¬¬3æ­¥: åˆå§‹åŒ–æ¶ˆèæµ‹è¯•å™¨
    logger.info("\n[3] åˆå§‹åŒ–æ¶ˆèæµ‹è¯•å™¨...")
    try:
        tester = LoRAAblusionTester(model, num_layers=28, device=args.device)
        tester.save_lora_weights()
        logger.info("   âœ… æ¶ˆèæµ‹è¯•å™¨åˆå§‹åŒ–å®Œæˆ")
    except Exception as e:
        logger.error(f"   âŒ æ¶ˆèæµ‹è¯•å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # ç¬¬4æ­¥: åˆå§‹åŒ–æ¢é’ˆè¯„ä¼°å™¨
    logger.info("\n[4] åˆå§‹åŒ–æ¢é’ˆè¯„ä¼°å™¨...")
    try:
        evaluator = ProbeAccuracyEvaluator(model, probe_model, device=args.device)
        logger.info("   âœ… æ¢é’ˆè¯„ä¼°å™¨åˆå§‹åŒ–å®Œæˆ")
    except Exception as e:
        logger.error(f"   âŒ æ¢é’ˆè¯„ä¼°å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # ç¬¬5æ­¥: å®šä¹‰æ¶ˆèé…ç½®
    logger.info("\n[5] å®šä¹‰æ¶ˆèé…ç½®...")
    ablation_configs = {
        'baseline': [],
        'disable_layer_16': [16],
        'disable_layers_0_8': list(range(0, 9)),
        'disable_layers_8_16': list(range(8, 17)),
        'disable_layers_17_27': list(range(17, 28)),
    }
    logger.info(f"   å®šä¹‰äº† {len(ablation_configs)} ä¸ªé…ç½®")
    
    # ç¬¬6æ­¥: å‡†å¤‡æµ‹è¯•æ•°æ®
    logger.info("\n[6] å‡†å¤‡æµ‹è¯•æ•°æ®...")
    # è¿™é‡Œåº”è¯¥ä»çœŸå®æ•°æ®é›†åŠ è½½
    test_prompts = ["test prompt"] * 10
    test_labels = [0, 1] * 5  # äºŒåˆ†ç±»ç¤ºä¾‹
    logger.info(f"   æµ‹è¯•æ•°æ®: {len(test_prompts)} ä¸ªæ ·æœ¬")
    
    # ç¬¬7æ­¥: è¿è¡Œæ¶ˆèå¾ªç¯
    logger.info("\n[7] è¿è¡Œæ¶ˆèå®éªŒ...")
    results = {}
    
    for config_idx, (config_name, disabled_layers) in enumerate(ablation_configs.items(), 1):
        logger.info(f"\n   [{config_idx}/{len(ablation_configs)}] {config_name}")
        
        try:
            # ç¦ç”¨LoRA
            tester.disable_lora_on_layers(disabled_layers)
            
            # è¯„ä¼°æ¢é’ˆå‡†ç¡®ç‡
            probe_acc = evaluator.evaluate_probe_accuracy(test_prompts, test_labels)
            logger.info(f"      æ¢é’ˆå‡†ç¡®ç‡: {probe_acc:.4f}")
            
            results[config_name] = {
                'disabled_layers': disabled_layers,
                'probe_accuracy': probe_acc,
                'timestamp': datetime.now().isoformat(),
            }
        except Exception as e:
            logger.error(f"      âœ— é”™è¯¯: {e}")
            results[config_name] = {'error': str(e)}
        
        # æ¢å¤LoRA
        tester.restore_lora_on_layers(disabled_layers)
    
    # ç¬¬8æ­¥: ä¿å­˜ç»“æœ
    logger.info("\n[8] ä¿å­˜ç»“æœ...")
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    full_results = {
        'experiment': 'lora_ablation_probes',
        'model': args.model_path,
        'timestamp': datetime.now().isoformat(),
        'ablation_results': results,
    }
    
    results_file = output_dir / "ablation_probe_results.json"
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(full_results, f, indent=2, ensure_ascii=False)
    logger.info(f"   âœ… ç»“æœä¿å­˜åˆ°: {results_file}")
    
    # ç¬¬9æ­¥: æ‰“å°æ€»ç»“
    logger.info("\n" + "=" * 70)
    logger.info("ğŸ“Š æ¢é’ˆå‡†ç¡®ç‡æµ‹è¯•ç»“æœ")
    logger.info("=" * 70 + "\n")
    
    print(f"{'é…ç½®':<30} | {'æ¢é’ˆå‡†ç¡®ç‡':<12} | {'ç›¸å¯¹åŸºå‡†':<12}")
    print("-" * 60)
    
    baseline_acc = results.get('baseline', {}).get('probe_accuracy', 0)
    for config_name, result in sorted(results.items()):
        if 'error' in result:
            print(f"{config_name:<30} | ERROR")
            continue
        
        acc = result['probe_accuracy']
        if baseline_acc > 0:
            ratio = f"{(acc - baseline_acc) / baseline_acc * 100:+.1f}%"
        else:
            ratio = "N/A"
        
        print(f"{config_name:<30} | {acc:12.4f} | {ratio:>12s}")
    
    logger.info("\nâœ… å®éªŒå®Œæˆ!\n")


def main():
    parser = argparse.ArgumentParser(description='LoRAæ¶ˆèæµ‹è¯• - æ¢é’ˆå‡†ç¡®ç‡ç‰ˆæœ¬')
    parser.add_argument('--model_path', type=str, default='Qwen/Qwen2.5-1.5B-Instruct',
                        help='åŸºç¡€æ¨¡å‹è·¯å¾„')
    parser.add_argument('--lora_path', type=str, required=True,
                        help='LoRAé€‚é…å™¨è·¯å¾„')
    parser.add_argument('--probe_path', type=str, required=True,
                        help='æ¢é’ˆæ¨¡å‹è·¯å¾„')
    parser.add_argument('--gpu', type=str, default='0',
                        help='GPUè®¾å¤‡å·')
    parser.add_argument('--device', type=str, default='cuda:0',
                        help='PyTorchè®¾å¤‡')
    parser.add_argument('--output_dir', type=str, default='./results/ablation_probes',
                        help='è¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    run_ablation_experiment(args)


if __name__ == "__main__":
    main()
